{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tynan 548 Project File\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Libaries and Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cvxpy as cp # import cvxpy\n",
    "\n",
    "# in this problem, we will use the dynamaxsys library to import dynamical systems implemented in JAX: https://github.com/UW-CTRL/dynamaxsys\n",
    "from dynamaxsys.simplecar import DynamicallyExtendedSimpleCar\n",
    "from dynamaxsys.base import get_discrete_time_dynamics\n",
    "from dynamaxsys.utils import linearize\n",
    "\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import numpy as np\n",
    "import functools\n",
    "from ipywidgets import interact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the robot dynamics\n",
    "wheelbase = 1.0\n",
    "dt = 0.1\n",
    "ct_robot_dynamics = DynamicallyExtendedSimpleCar(wheelbase=wheelbase) # robot dynamics\n",
    "dt_robot_dynamics = get_discrete_time_dynamics(ct_robot_dynamics, dt=dt) # discrete time dynamics\n",
    "state_dim = dt_robot_dynamics.state_dim\n",
    "control_dim = dt_robot_dynamics.control_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamics and goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the problem parameters\n",
    "planning_horizon = 20 # 20 # length of the planning horizon\n",
    "num_time_steps = 5 # number of time steps to simulate\n",
    "num_sqp_iterations = 15 # 15 # number of SQP iterations\n",
    "t = 0. # this doesn't affect anything, but a value is needed \n",
    "\n",
    "# control and velocity limits\n",
    "v_max = 2.5 #2 m/s\n",
    "v_min = 0.05 # 0.2 m/s\n",
    "acceleration_max = 3.0 #2/-2  m/s/s\n",
    "acceleration_min = -3.0 # m/s/s\n",
    "steering_max = 2. #started 0.5/-0.5 # radians/sec\n",
    "steering_min = -2. # radians/sec\n",
    "\n",
    "# obstacle parameters\n",
    "\n",
    "robot_radius = 0.1 # robot radius\n",
    "goal_locations = [jnp.array([6.11, 1.44]), jnp.array([5.87, 1.19]), jnp.array([6.29, 0.84]), jnp.array([7.33, 0.15]), jnp.array([7.44, 3.35]), jnp.array([8.2, 7.6]), \n",
    "                jnp.array([0.87, 6.25]), jnp.array([0.20, 4.68]), jnp.array([-0.13, 5.23]), jnp.array([0.17, 4.77]), jnp.array([0.83, 6.18]), jnp.array([-2.28, 8.40])]\n",
    "goal_location = goal_locations[0]\n",
    "goal_radius = 0.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Establish Rectangle Class ## \n",
    "\n",
    "class Rectangle:\n",
    "    def __init__(self, center, length, width, buffer=0.15): # 0.4 # 0.25 buffer makes robot go narrow way\n",
    "        \"\"\"\n",
    "        Initialize a rectangular obstacle.\n",
    "\n",
    "        Args:\n",
    "            center (tuple or jnp.ndarray): (x, y) coordinates of the center.\n",
    "            length (float): Length along the x-axis.\n",
    "            width (float): Width along the y-axis.\n",
    "            buffer (float): Optional buffer space for inflation.\n",
    "        \"\"\"\n",
    "        self.center = jnp.array(center)\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "        self.buffer = buffer\n",
    "\n",
    "    def inflated_half_lengths(self):\n",
    "        return (self.length / 2 + self.buffer, self.width / 2 + self.buffer)\n",
    "\n",
    "    def as_array(self):\n",
    "        \"\"\"Returns center and dimensions as a single array.\"\"\"\n",
    "        return jnp.array([*self.center, self.length, self.width, self.buffer])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Rectangle(center={self.center.tolist()}, l={self.length}, w={self.width}, buffer={self.buffer})\"\n",
    "\n",
    "\n",
    "\n",
    "## Establish Circle Class ## \n",
    "\n",
    "class Circle:\n",
    "    def __init__(self, center, radius, buffer=0.2): # 0.4 # 0.25 buffer makes robot go narrow way\n",
    "        \"\"\"\n",
    "        Initialize a circular obstacle.\n",
    "\n",
    "        Args:\n",
    "            center (tuple or jnp.ndarray): (x, y) coordinates of the center.\n",
    "            radius (float)\n",
    "            buffer (float): Optional buffer space for inflation.\n",
    "        \"\"\"\n",
    "        self.center = jnp.array(center)\n",
    "        self.radius = radius\n",
    "        self.buffer = buffer\n",
    "\n",
    "    def as_array(self):\n",
    "        \"\"\"Returns center and dimensions as a single array.\"\"\"\n",
    "        return jnp.array([*self.center, self.radius, self.buffer])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Circle(center={self.center.tolist()}, buffer={self.buffer})\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Obstacles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Init Constraint Objects\n",
    "\n",
    "\n",
    "## Rectangle Obstacles\n",
    "rectangles = [\n",
    "    #Rectangle(center=(0.2, 6.0), length=0.6, width=0.6),\n",
    "    #Rectangle(center=(-0.2, 6.4), length=0.6, width=0.6),\n",
    "    Rectangle(center=(4.0, 2.0), length=0.5, width=0.5)\n",
    "]\n",
    "\n",
    "## Circle caps for rectangle obstacles\n",
    "circles = [\n",
    "    Circle(center=(6.8, 2.2), radius=0.8),\n",
    "    Circle(center=(6.0, 3.6), radius=1.2),\n",
    "    Circle(center=(6.9, 5.8), radius=1.7),\n",
    "    Circle(center=(7.1, 4.0), radius=0.3),\n",
    "    Circle(center=(4.7, 4.3), radius=1.6),\n",
    "    Circle(center=(2.8, 8.9), radius=2.2),\n",
    "    Circle(center=(0.3, 5.8), radius=0.35),\n",
    "    Circle(center=(0.0, 6.3), radius=0.35),    \n",
    "    Circle(center=(-0.3, 6.8), radius=0.35), # breaking?\n",
    "    Circle(center=(-0.55, 7.2), radius=0.35),\n",
    "    Circle(center=(-0.8, 7.7), radius=0.35),\n",
    "    Circle(center=(-1.4, 7.2), radius=1.0), \n",
    "    Circle(center=(2.0, 2.6), radius=0.8) #no\n",
    "]\n",
    "\n",
    "## Background circles, not part of calculation\n",
    "circ_bg = []\n",
    "\n",
    "\n",
    "## Rectangle CBF ##\n",
    "CBF_object = Rectangle(center=(3.0,4.5), length=14.0, width=9.0) #boundary robot stays within\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS #\n",
    "\n",
    "# define obstacle function g(x) >= 0\n",
    "# where g(x) is the distance from the obstacle\n",
    "@jax.jit\n",
    "def circle_constraint(state, obstacle, radius, buffer):\n",
    "    return jnp.linalg.norm(state[:2] - obstacle[:2]) - radius - buffer\n",
    "\n",
    "\n",
    "def smooth_max(a, b, alpha=5.0):\n",
    "    return (1/alpha) * jnp.log(jnp.exp(alpha * a) + jnp.exp(alpha * b))\n",
    "\n",
    "@jax.jit\n",
    "def rect_constraint_smooth(state, obstacle, l, w, buffer, alpha=5.0):\n",
    "    dx = jnp.abs(state[0] - obstacle[0]) - l / 2 - buffer\n",
    "    dy = jnp.abs(state[1] - obstacle[1]) - w / 2 - buffer\n",
    "    return smooth_max(dx, dy, alpha=alpha)\n",
    "\n",
    "# define goal function g(x) >= 0\n",
    "# where g(x) is the distance from the goal\n",
    "\n",
    "@jax.jit\n",
    "def goal_constraint(state, goal, radius):\n",
    "    return jnp.linalg.norm(state[:2] - goal[:2]) - radius\n",
    "\n",
    "\n",
    "# function to simulate the discrete time dynamics given initial state and control sequence\n",
    "@functools.partial(jax.jit, static_argnames=[\"dt_dynamics\"])\n",
    "def simulate_discrete_time_dynamics(dt_dynamics, state, controls, t0, dt):\n",
    "    states = [state]\n",
    "    t = t0\n",
    "    for c in controls:\n",
    "\n",
    "        state = dt_dynamics(state, c, t)\n",
    "        states.append(state)\n",
    "        t += dt\n",
    "    return jnp.stack(states)\n",
    "\n",
    "# function to simulate the discrete time dynamics given initial state and control sequence\n",
    "# function slightly modified to add noise \n",
    "@functools.partial(jax.jit, static_argnames=[\"dt_dynamics\"])\n",
    "def simulate_discrete_time_dynamics_with_noise(dt_dynamics, state, controls, t0, dt, noises):\n",
    "    states = [state]\n",
    "    t = t0\n",
    "    for (c,noise) in zip(controls, noises):\n",
    "        state = dt_robot_dynamics(state, c, t + noise * dt) # take out noises for now\n",
    "        states.append(state)\n",
    "        t += dt\n",
    "    return jnp.stack(states, -1)\n",
    "\n",
    "# jit the linearize constraint functions to make it run faster\n",
    "linearize_circle = jax.jit(jax.vmap(jax.grad(circle_constraint), in_axes=[0, None, None, None]))\n",
    "linearize_goal = jax.jit(jax.vmap(jax.grad(goal_constraint), in_axes=[0, None, None]))\n",
    "linearize_rect_smooth = jax.jit(\n",
    "    jax.vmap(jax.grad(rect_constraint_smooth, argnums=0), in_axes=[0, None, None, None, None])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem construction. \n",
    "\n",
    "Two things I am missing: a CLF-type function adding stability in converging to goals. Add threshold for distance where robot starts to consider obstacles as part of constraint. Currently, robot sees all obstacles at all times, which can lead to some unpredictable behavior when adjusting objects far away from initial robot position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up cvxpy problem variables and parameters\n",
    "xs = cp.Variable([planning_horizon+1, state_dim])  # cvx variable for states\n",
    "us = cp.Variable([planning_horizon, control_dim])  # cvx variable for controls\n",
    "slack = cp.Variable(1) # slack variable to make sure the problem is feasible\n",
    "As = [cp.Parameter([state_dim, state_dim]) for _ in range(planning_horizon)]  # parameters for linearized dynamics\n",
    "Bs = [cp.Parameter([state_dim, control_dim]) for _ in range(planning_horizon)] # parameters for linearized dynamics\n",
    "Cs = [cp.Parameter([state_dim]) for _ in range(planning_horizon)] # parameters for linearized dynamics\n",
    "\n",
    "\n",
    "Gs_circs = [[cp.Parameter([state_dim]) for _ in range(planning_horizon + 1)] for _ in range(len(circles))]\n",
    "hs_circs = [[cp.Parameter(1) for _ in range(planning_horizon + 1)] for _ in range(len(circles))]\n",
    "\n",
    "#Gs_rects = [[cp.Parameter([state_dim]) for _ in range(planning_horizon + 1)] for _ in range(len(rectangles))]\n",
    "#hs_rects = [[cp.Parameter(1) for _ in range(planning_horizon + 1)] for _ in range(len(rectangles))]\n",
    "\n",
    "Gs_CBF = [cp.Parameter([state_dim]) for _ in range(planning_horizon+1)] # parameters for linearized constraints CBF\n",
    "hs_CBF = [cp.Parameter(1) for _ in range(planning_horizon+1)] # parameters for linearized constraints CBF\n",
    "\n",
    "\n",
    "Goal_Gs = [cp.Parameter([state_dim]) for _ in range(planning_horizon+1)] # parameters for linearized constraints\n",
    "Goal_hs = [cp.Parameter(1) for _ in range(planning_horizon+1)] # parameters for linearized constraints\n",
    "\n",
    "xs_previous = cp.Parameter([planning_horizon+1, state_dim]) # parameter for previous solution\n",
    "us_previous = cp.Parameter([planning_horizon, control_dim]) # parameter for previous solution\n",
    "initial_state = cp.Parameter([state_dim]) # parameter for current robot state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up cvxpy problem cost and constraints\n",
    "def construct_problem(goal_location):\n",
    "    beta1 = 0.2 # coefficient for control effort\n",
    "    beta2 = 5. # coefficient for progress\n",
    "    beta3 = 10. # coefficient for trust region\n",
    "    slack_penalty = 1000. # coefficient for slack variable\n",
    "    markup = 1.0\n",
    "    goal_cost_weight = 15. # 10\n",
    "    forward_velocity_weight = 0.1 # prev 0.1 # encourage robot to keep moving forward\n",
    "    v_min = 0.0\n",
    "    proximity_buffer = .7 # prox DISTANCE of robot to obstacles, soft discourage\n",
    "    proximity_weight = 3.\n",
    "    turning_penalty = 3.0\n",
    "\n",
    "\n",
    "    # Discourages large changes in state and control\n",
    "    objective = beta3 * (cp.sum_squares(xs - xs_previous) + cp.sum_squares(us - us_previous)) + slack_penalty * slack**2\n",
    "\n",
    "    constraints = [xs[0] == initial_state, slack >= 0] # initial state and slack constraint\n",
    "    for t in range(planning_horizon):\n",
    "        objective += (beta1 * cp.sum_squares(us[t]) ) * markup**t # only penalizes control effort\n",
    "        #terminal_goal_dist_sq = cp.sum_squares(xs[planning_horizon, :2] - goal_location) * markup**t\n",
    "        #objective += terminal_goal_weight * terminal_goal_dist_sq\n",
    "\n",
    "\n",
    "            # Encourage steady progress toward the goal\n",
    "        step_goal_dist_sq = cp.sum_squares(xs[t, :2] - goal_location)\n",
    "        objective += goal_cost_weight * step_goal_dist_sq * markup**t\n",
    "        objective += -forward_velocity_weight * cp.sum(xs[:, 2]) * markup # encourages movement\n",
    "\n",
    "        constraints += [xs[t+1] == As[t] @ xs[t] + Bs[t] @ us[t] + Cs[t]] # dynamics constraint\n",
    "        constraints += [xs[t,-1] <= v_max, xs[t,-1] >= v_min, us[t,1] <= acceleration_max, us[t,1] >= acceleration_min, us[t,0] <= steering_max, us[t,0] >= steering_min] # control and velocity limit constraints\n",
    "        \n",
    "        # Penalize sharp changes in direction\n",
    "        heading_diff = xs[t+1, 2] - xs[t, 2]\n",
    "        objective += turning_penalty * cp.sum_squares(heading_diff)\n",
    "\n",
    "        # Soft penalize going close to obstacles\n",
    "        #for r_idx in range(len(Gs_rects)):\n",
    "        #    constraints += [Gs_rects[r_idx][t] @ xs[t] + hs_rects[r_idx][t] >= 0]\n",
    "        #    dist = Gs_rects[r_idx][t] @ xs[t] + hs_rects[r_idx][t]\n",
    "        #    # Penalty if within 1m of obstacle edge: (1 - dist)^2 if dist < 1\n",
    "        #    objective += proximity_weight * cp.pos(proximity_buffer - dist)**2\n",
    "\n",
    "        #for r_idx in range(len(Gs_circs)):\n",
    "        #    constraints += [Gs_circs[r_idx][t] @ xs[t] + hs_circs[r_idx][t] >= 0]\n",
    "        #    dist = Gs_circs[r_idx][t] @ xs[t] + hs_circs[r_idx][t]\n",
    "            # Penalty if within 1m of obstacle edge: (1 - dist)^2 if dist < 1\n",
    "        #    objective += proximity_weight * cp.pos(proximity_buffer - dist)**3\n",
    "\n",
    "        # Robot only sees obstacles if they are within a certain distance\n",
    "        for r_idx in range(len(Gs_circs)):\n",
    "            # Estimate distance from previous state\n",
    "            robot_pos = xs_previous[t, :2].value if xs_previous[t, :2].value is not None else np.zeros(2)\n",
    "            obstacle_center = circles[r_idx].center  # You need this list of centers\n",
    "            distance = np.linalg.norm(robot_pos - obstacle_center)\n",
    "\n",
    "            if distance < 6.0: # set vision distance, has to be greater than largest object diameter + buffer\n",
    "                # Only add constraints and penalties if within range\n",
    "                # This significantly decreases compiling time\n",
    "                constraints += [Gs_circs[r_idx][t] @ xs[t] + hs_circs[r_idx][t] >= 0]\n",
    "                dist = Gs_circs[r_idx][t] @ xs[t] + hs_circs[r_idx][t]\n",
    "                objective += proximity_weight * cp.pos(proximity_buffer - dist)**3\n",
    "\n",
    "\n",
    "        # CBF, rectangle allowable traversable range\n",
    "        constraints += [Gs_CBF[t] @ xs[t] + hs_CBF[t] <= 0]\n",
    "\n",
    "    #####\n",
    "    constraints += [xs[planning_horizon,-1] <= v_max, xs[planning_horizon,-1] >= v_min] #,\n",
    "                #Gs[planning_horizon] @ xs[planning_horizon] + hs[planning_horizon] >= -slack]\n",
    "\n",
    "    # Process rectangular obstacles final timestep\n",
    "    #for r_idx in range(len(Gs_rects)):\n",
    "    #    constraints += [Gs_rects[r_idx][planning_horizon] @ xs[planning_horizon] + hs_rects[r_idx][planning_horizon] >= -slack]\n",
    "\n",
    "    # Process circular obstacles final timestep\n",
    "    for r_idx in range(len(Gs_circs)):\n",
    "        constraints += [Gs_circs[r_idx][planning_horizon] @ xs[planning_horizon] + hs_circs[r_idx][planning_horizon] >= 0]\n",
    "\n",
    "    return cp.Problem(cp.Minimize(objective), constraints) # construct problem\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial states\n",
    "robot_state = jnp.array([goal_locations[0][0], goal_locations[0][1], 0., 1.])  # robot starting state 92.38, 0.0977\n",
    "\n",
    "robot_trajectory = [robot_state] # list to collect robot's state as it replans\n",
    "sqp_list = [] # list to collect each sqp iteration \n",
    "robot_control_list = []  # list to collect robot's constrols as it replans\n",
    "robot_trajectory_list = [] # list to collect robot's planned trajectories\n",
    "\n",
    "# initial robot planned state and controls\n",
    "previous_controls = jnp.zeros([planning_horizon, control_dim]) # initial guess for robot controls\n",
    "previous_states =  simulate_discrete_time_dynamics(dt_robot_dynamics, robot_state, previous_controls, 0., dt) # initial guess for robot states\n",
    "xs_previous.value = np.array(previous_states) # set xs_previous parameter value\n",
    "us_previous.value = np.array(previous_controls) # set us_previous parameter value \n",
    "\n",
    "# precompute the noise\n",
    "key = jax.random.PRNGKey(0)\n",
    "noise_covar = jnp.diag(jnp.array([0.1, 0.1, 0.05, 0.2])) # noise covariance\n",
    "noises = jax.random.multivariate_normal(key, jnp.zeros(robot_state.shape), noise_covar, shape=(num_time_steps,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point 0 sampled at sol 0. Searching for Point 1 at [5.87 1.19].\n",
      "Point 1 sampled at sol 2. Searching for Point 2 at [6.29 0.84].\n",
      "Point 2 sampled at sol 7. Searching for Point 3 at [7.33 0.15].\n",
      "Point 3 sampled at sol 16. Searching for Point 4 at [7.44 3.35].\n",
      "Point 4 sampled at sol 33. Searching for Point 5 at [8.2 7.6].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ariel\\anaconda3\\envs\\ME548\\Lib\\site-packages\\cvxpy\\problems\\problem.py:1504: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point 5 sampled at sol 56. Searching for Point 6 at [0.87 6.25].\n",
      "Point 6 sampled at sol 89. Searching for Point 7 at [0.2  4.68].\n",
      "Point 7 sampled at sol 99. Searching for Point 8 at [-0.13  5.23].\n",
      "Point 8 sampled at sol 104. Searching for Point 9 at [0.17 4.77].\n",
      "Point 9 sampled at sol 108. Searching for Point 10 at [0.83 6.18].\n",
      "Point 10 sampled at sol 119. Searching for Point 11 at [-2.28  8.4 ].\n",
      "Point 11 sampled at sol 139. All goals reached!\n"
     ]
    }
   ],
   "source": [
    "prob = construct_problem(goal_location)\n",
    "goal_index = 0\n",
    "#for t in range(num_time_steps):\n",
    "t = 0\n",
    "while goal_index < len(goal_locations): #iterate through until reached end goal\n",
    "    goal_threshold = 0.20  # set working at 0.20\n",
    "    distance_to_goal = np.linalg.norm(robot_state[:2] - goal_location)\n",
    "    if distance_to_goal < goal_threshold:\n",
    "        if goal_index < len(goal_locations) - 1: #stop resetting goal after last goal reached\n",
    "            goal_location = goal_locations[goal_index + 1]\n",
    "            print(f\"Point {goal_index} sampled at sol {t}. Searching for Point {goal_index + 1} at {goal_location}.\")\n",
    "            goal_index += 1\n",
    "                    \n",
    "        else:\n",
    "            print(f\"Point {goal_index} sampled at sol {t}. All goals reached!\")\n",
    "            break\n",
    "\n",
    "        # Reset velocity\n",
    "        #robot_state = robot_state.at[-1].set(0)\n",
    "\n",
    "        # Reorient toward next goal\n",
    "        #robot_control[:] = 0\n",
    "        delta = goal_location - robot_state[:2]\n",
    "        new_heading = np.arctan2(delta[1], delta[0])\n",
    "        robot_state = robot_state.at[2].set(new_heading)\n",
    "\n",
    "        prob = construct_problem(goal_location)  # rebuild with new goal\n",
    "        solver = cp.CLARABEL\n",
    "\n",
    "        previous_states = np.tile(np.array(robot_state), (planning_horizon + 1, 1))\n",
    "        previous_controls = np.zeros((planning_horizon, control_dim))\n",
    "    t += 1 # \n",
    "    \n",
    "    initial_state.value = np.array(robot_state)\n",
    "    sqp_solutions = [previous_states]\n",
    "\n",
    "    \n",
    "    for i in range(num_sqp_iterations):\n",
    "        #print(\"goal location in sqp loop:\", goal_location)\n",
    "        As_value, Bs_value, Cs_value = jax.vmap(linearize, in_axes=[None, 0, 0, None])(dt_robot_dynamics, previous_states[:-1], previous_controls, 0.)\n",
    "        #Gs_value = linearize_obstacle(previous_states, obstacle_location, obstacle_radius + robot_radius) \n",
    "        #hs_value = jax.vmap(obstacle_constraint, [0, None, None])(previous_states, obstacle_location, obstacle_radius + robot_radius) - jax.vmap(jnp.dot, [0, 0])(Gs_value, previous_states)\n",
    "    \n",
    "        # Init vectors for batch rectangle and circle obstacles\n",
    "        #Gs_rects_values = []\n",
    "        #hs_rects_values = []\n",
    "        Gs_circs_values = []\n",
    "        hs_circs_values = []\n",
    "\n",
    "        #for rect in rectangles:\n",
    "        #    G_val = linearize_rect_smooth(previous_states, rect.center, rect.length, rect.width, rect.buffer)\n",
    "        #    h_val = (\n",
    "        #        jax.vmap(rect_constraint_smooth, [0, None, None, None, None])(previous_states, rect.center, rect.length, rect.width, rect.buffer)\n",
    "        #        - jax.vmap(jnp.dot, [0, 0])(G_val, previous_states)\n",
    "        #    )\n",
    "        #    Gs_rects_values.append(G_val)\n",
    "        #    hs_rects_values.append(h_val)\n",
    "\n",
    "        for circ in circles:\n",
    "            G_val = linearize_circle(previous_states, circ.center, circ.radius, circ.buffer)\n",
    "            h_val = (\n",
    "                jax.vmap(circle_constraint, [0, None, None, None])(previous_states, circ.center, circ.radius, circ.buffer)\n",
    "                - jax.vmap(jnp.dot, [0, 0])(G_val, previous_states)\n",
    "            )\n",
    "            Gs_circs_values.append(G_val)\n",
    "            hs_circs_values.append(h_val)\n",
    "\n",
    "\n",
    "        Gs_CBF_value = linearize_rect_smooth(previous_states, CBF_object.center, CBF_object.length, CBF_object.width, CBF_object.buffer)\n",
    "        hs_CBF_value = (\n",
    "                jax.vmap(rect_constraint_smooth, [0, None, None, None, None])(previous_states, CBF_object.center, CBF_object.length, CBF_object.width, CBF_object.buffer)\n",
    "                - jax.vmap(jnp.dot, [0, 0])(Gs_CBF_value, previous_states))\n",
    "\n",
    "\n",
    "        Goal_Gs_value = linearize_goal(previous_states, goal_location, goal_radius + robot_radius) \n",
    "        Goal_hs_value = jax.vmap(goal_constraint, [0, None, None])(previous_states, goal_location, goal_radius + robot_radius) - jax.vmap(jnp.dot, [0, 0])(Goal_Gs_value, previous_states)\n",
    "\n",
    "        for i in range(planning_horizon):\n",
    "            As[i].value = np.array(As_value[i])\n",
    "            Bs[i].value = np.array(Bs_value[i])\n",
    "            Cs[i].value = np.array(Cs_value[i])\n",
    "\n",
    "            Goal_Gs[i].value = np.array(Goal_Gs_value[i])\n",
    "            Goal_hs[i].value = np.array(Goal_hs_value[i:i+1])\n",
    "\n",
    "                # Handle all rectangle and circle constraints\n",
    "            #for r_idx in range(len(rectangles)):\n",
    "            #    Gs_rects[r_idx][i].value = np.array(Gs_rects_values[r_idx][i])\n",
    "            #    hs_rects[r_idx][i].value = np.array(hs_rects_values[r_idx][i:i+1])\n",
    "\n",
    "            for r_idx in range(len(circles)):\n",
    "                Gs_circs[r_idx][i].value = np.array(Gs_circs_values[r_idx][i])\n",
    "                hs_circs[r_idx][i].value = np.array(hs_circs_values[r_idx][i:i+1])\n",
    "\n",
    "            Gs_CBF[i].value = np.array(Gs_CBF_value[i])\n",
    "            hs_CBF[i].value = np.array(hs_CBF_value[i:i+1])\n",
    "\n",
    "\n",
    "        Goal_Gs[planning_horizon].value = np.array(Goal_Gs_value[planning_horizon])\n",
    "        Goal_hs[planning_horizon].value = np.array(Goal_hs_value[planning_horizon:planning_horizon+1])\n",
    "\n",
    "        #for r_idx in range(len(rectangles)):\n",
    "        #    Gs_rects[r_idx][planning_horizon].value = np.array(Gs_rects_values[r_idx][planning_horizon])\n",
    "        #    hs_rects[r_idx][planning_horizon].value = np.array(hs_rects_values[r_idx][planning_horizon:planning_horizon+1])\n",
    "\n",
    "        for r_idx in range(len(circles)):\n",
    "            Gs_circs[r_idx][planning_horizon].value = np.array(Gs_circs_values[r_idx][planning_horizon])\n",
    "            hs_circs[r_idx][planning_horizon].value = np.array(hs_circs_values[r_idx][planning_horizon:planning_horizon+1])\n",
    "\n",
    "        Gs_CBF[planning_horizon].value = np.array(Gs_CBF_value[planning_horizon])\n",
    "        hs_CBF[planning_horizon].value = np.array(hs_CBF_value[planning_horizon:planning_horizon+1])\n",
    "\n",
    "\n",
    "        result = prob.solve(\n",
    "            solver=cp.CLARABEL,\n",
    "        )\n",
    "\n",
    "        if us.value is None:\n",
    "            #print(\"No solution found\")\n",
    "            break\n",
    "\n",
    "        previous_controls = us.value\n",
    "        previous_states =  simulate_discrete_time_dynamics(dt_robot_dynamics, robot_state, previous_controls, 0., dt)\n",
    "        sqp_solutions.append(previous_states)\n",
    "        xs_previous.value = np.array(previous_states)\n",
    "        us_previous.value = np.array(previous_controls)\n",
    "\n",
    "    sqp_list.append(np.stack(sqp_solutions))\n",
    "    robot_control = previous_controls[0]\n",
    "    robot_control_list.append(robot_control)\n",
    "    \n",
    "    # get the robot next state using the control input\n",
    "    robot_state = dt_robot_dynamics(robot_state, robot_control, noises[t] * dt) \n",
    "    \n",
    "    # clipping the robot velocity so the problem doesn't become infeasible at the next step\n",
    "    robot_state = robot_state.at[3].set(jnp.clip(robot_state[3], v_min, v_max)) \n",
    "    \n",
    "    # add robot state and trajectory to the list\n",
    "    robot_trajectory.append(robot_state)\n",
    "    robot_trajectory_list.append(previous_states)\n",
    "    \n",
    "    # update the previous states and controls for the next iteration\n",
    "    previous_states =  simulate_discrete_time_dynamics(dt_robot_dynamics, robot_state, previous_controls, 0., dt)\n",
    "\n",
    "robot_trajectory = jnp.stack(robot_trajectory)\n",
    "robot_controls = jnp.stack(robot_control_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16d283487aa4156a1e70cea153c04b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=69, description='i', max=138), IntSlider(value=7, description='j', max=1â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the results. No need to add comments here. Just run this cell to visualize the results\n",
    "@interact(i=(0,t-1), j=(0,num_sqp_iterations-1))\n",
    "\n",
    "def plot(i, j):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(24, 8), gridspec_kw={'width_ratios': [2, 1]})\n",
    "    # fig, axs = plt.subplots(1,2, figsize=(10, 4))\n",
    "    ax = axs[0]\n",
    "    robot_position = robot_trajectory[i, :2]\n",
    "    \n",
    "    # plot goals\n",
    "    for count in range(0, len(goal_locations)):\n",
    "        ax.add_patch(plt.Circle(goal_locations[count], goal_radius+.05, color='C2', alpha=0.6))\n",
    "                \n",
    "        # Add goal index label at the center\n",
    "        ax.text(\n",
    "            goal_locations[count][0],                # x-coordinate\n",
    "            goal_locations[count][1],                # y-coordinate\n",
    "            str(count),                                 # text to display\n",
    "            color='black',                              # text color\n",
    "            fontsize=10,                                # size of the number\n",
    "            ha='center',                                # horizontal alignment\n",
    "            va='center',                                # vertical alignment\n",
    "            fontweight='bold'\n",
    "        )\n",
    "    \n",
    "    #for count in range(0, len(rectangles)):\n",
    "    #    bottom_left = rectangles[count].center - jnp.array([rectangles[count].length / 2, rectangles[count].width / 2])\n",
    "    #    rect_plot = patches.Rectangle(\n",
    "    #        bottom_left,\n",
    "    #        rectangles[count].length,            # length along x\n",
    "    #        rectangles[count].width,            # width along y\n",
    "    #        linewidth=1,\n",
    "    #        edgecolor='#b04a00',\n",
    "    #        facecolor='#b04a00',\n",
    "    #        alpha=1.0\n",
    "    #    )\n",
    "    #    ax.add_patch(rect_plot)\n",
    "\n",
    "    #    # Add rectangle index label at the center\n",
    "    #    ax.text(\n",
    "    #        rectangles[count].center[0],                # x-coordinate\n",
    "    #        rectangles[count].center[1],                # y-coordinate\n",
    "    #        str( ''),                                 # text to display\n",
    "    #        color='black',                              # text color\n",
    "    #        fontsize=10,                                # size of the number\n",
    "    #        ha='center',                                # horizontal alignment\n",
    "    #        va='center',                                # vertical alignment\n",
    "    #        fontweight='bold'\n",
    "    #    )\n",
    "\n",
    "    for count in range(0, len(circles)):\n",
    "        circ_plot = patches.Circle(circles[count].center, circles[count].radius, color='#b04a00', alpha=1.0)\n",
    "        ax.add_patch(circ_plot)\n",
    "        # Add rectangle index label at the center\n",
    "        ax.text(\n",
    "            circles[count].center[0],                # x-coordinate\n",
    "            circles[count].center[1],                # y-coordinate\n",
    "            str(''),                                 # text to display\n",
    "            color='black',                              # text color\n",
    "            fontsize=10,                                # size of the number\n",
    "            ha='center',                                # horizontal alignment\n",
    "            va='center',                                # vertical alignment\n",
    "            fontweight='bold'\n",
    "        )\n",
    "\n",
    "    # Plot CBF object\n",
    "    bottom_left = CBF_object.center - jnp.array([CBF_object.length / 2, CBF_object.width / 2])\n",
    "    rect_plot = patches.Rectangle(\n",
    "        bottom_left,\n",
    "        CBF_object.length,            # length along x\n",
    "        CBF_object.width,            # width along y\n",
    "        linewidth=1,\n",
    "        edgecolor='C2',\n",
    "        facecolor='#b04a00',\n",
    "        alpha=0.25\n",
    "    )\n",
    "    ax.add_patch(rect_plot)\n",
    "\n",
    "    ax.plot(robot_trajectory[:,0], robot_trajectory[:,1], \"o-\", markersize=1, color='grey')\n",
    "    ax.plot(robot_trajectory_list[i][:,0], robot_trajectory_list[i][:,1], \"o-\", markersize=3, color='red', label=\"Planned\")\n",
    "    # Plot planned trajectory for the selected SQP iteration\n",
    "\n",
    "    #planned_trajectory = sqp_list[i][j]\n",
    "\n",
    "    if i < len(sqp_list) and j < len(sqp_list[i]):\n",
    "        planned_trajectory = sqp_list[i][j]\n",
    "        #ax.plot(planned_trajectory[:, 0], planned_trajectory[:, 1], \"o-\", markersize=3, color='green', alpha=0.4, label=f\"SQP iteration {j}\", label=f\"Sol {i}\")\n",
    "        ax.plot(\n",
    "        planned_trajectory[:, 0],\n",
    "        planned_trajectory[:, 1],\n",
    "        \"o-\",\n",
    "        markersize=3,\n",
    "        color='green',\n",
    "        alpha=0.4,\n",
    "        label=f\"Sol {i}, SQP {j}\"\n",
    ")\n",
    "    \n",
    "    \n",
    "    #else:\n",
    "    #    ax.text(0.5, 0.5, f\"No SQP {j} at step {i}\", transform=ax.transAxes, ha='center', va='center', fontsize=12, color='red')\n",
    "\n",
    "    #ax.plot(planned_trajectory[:, 0], planned_trajectory[:, 1], \"o-\", markersize=3, color='green', alpha=0.4, label=\"SQP iteration %d\" % j)\n",
    "    ax.scatter(robot_trajectory[i:i+1,0], robot_trajectory[i:i+1,1], s=30,  color='C100', label=\"Robot\")\n",
    "   \n",
    "    x_center, y_center = CBF_object.center\n",
    "    half_length = CBF_object.length / 2\n",
    "    half_width = CBF_object.width / 2\n",
    "\n",
    "    ax.set_xlim([x_center - half_length, x_center + half_length])\n",
    "    ax.set_ylim([y_center - half_width, y_center + half_width])\n",
    "    #ax.axis(\"equal\")\n",
    "    \n",
    "    ax.legend()\n",
    "\n",
    "    ax.set_title(\"heading=%.2f velocity=%.2f\"%(robot_trajectory[i,2], robot_trajectory[i,3]))\n",
    "    \n",
    "    x_center = float(CBF_object.center[0])\n",
    "    y_center = float(CBF_object.center[1])\n",
    "    half_length = float(CBF_object.length) / 2\n",
    "    half_width = float(CBF_object.width) / 2\n",
    "\n",
    "    ax.set_xlim(x_center - half_length, x_center + half_length)\n",
    "    ax.set_ylim(y_center - half_width, y_center + half_width)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "\n",
    "    ax = axs[1]\n",
    "    ax.plot(robot_controls)\n",
    "    ax.scatter([i], robot_controls[i:i+1, 0], label=\"$tan(\\\\delta)$\", color='C0')\n",
    "    ax.scatter([i], robot_controls[i:i+1, 1], label=\"Acceleration\", color='C1')\n",
    "\n",
    "    ax.hlines(steering_min, 0, t-1, color='C0', linestyle='--')\n",
    "    ax.hlines(steering_max, 0, t-1, color='C0', linestyle='--')\n",
    "    ax.hlines(acceleration_min, 0, t-1, color='C1', linestyle='--')\n",
    "    ax.hlines(acceleration_max, 0, t-1, color='C1', linestyle='--')\n",
    "    \n",
    "    ax.plot(robot_trajectory[:,-1], markersize=3, color='C2')\n",
    "    ax.scatter([i], robot_trajectory[i:i+1, 3], label=\"Velocity\", color='C2')\n",
    "    ax.hlines(v_min, 0, t-1, color='C2', linestyle='--')\n",
    "    ax.hlines(v_max, 0, t-1, color='C2', linestyle='--')\n",
    "    ax.set_xlim([0, t])\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.set_xlabel(\"Time step\")\n",
    "    ax.set_ylabel(\"Control\")\n",
    "    ax.set_title(\"Velocity, steering and acceleration\")\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.animation as animation\n",
    "import jax.numpy as jnp\n",
    "\n",
    "#fig, axs = plt.subplots(1, 1, figsize=(24, 8), gridspec_kw={'width_ratios': [2, 1]})\n",
    "fig, ax = plt.subplots(figsize=(24, 8))\n",
    "\n",
    "def animate(frame):\n",
    "    #axs[0].clear()\n",
    "    #axs[1].clear()\n",
    "    ax.clear()\n",
    "\n",
    "    i = frame // num_sqp_iterations\n",
    "    j = frame % num_sqp_iterations\n",
    "\n",
    "    #ax = axs[0]\n",
    "    robot_position = robot_trajectory[i, :2]\n",
    "\n",
    "    for count in range(len(goal_locations)):\n",
    "        ax.add_patch(plt.Circle(goal_locations[count], goal_radius+0.05, color='C2', alpha=0.6))\n",
    "        ax.text(*goal_locations[count], str(count), color='black', fontsize=10, ha='center', va='center', fontweight='bold')\n",
    "\n",
    "    for count in range(len(circles)):\n",
    "        circ = patches.Circle(circles[count].center, circles[count].radius, color='#b04a00', alpha=1.0)\n",
    "        ax.add_patch(circ)\n",
    "        ax.text(*circles[count].center, '', color='black', fontsize=10, ha='center', va='center', fontweight='bold')\n",
    "\n",
    "    bottom_left = CBF_object.center - jnp.array([CBF_object.length / 2, CBF_object.width / 2])\n",
    "    rect_plot = patches.Rectangle(bottom_left, CBF_object.length, CBF_object.width,\n",
    "                                  linewidth=1, edgecolor='C2', facecolor='#b04a00', alpha=0.25)\n",
    "    ax.add_patch(rect_plot)\n",
    "\n",
    "    ax.plot(robot_trajectory[:, 0], robot_trajectory[:, 1], \"o-\", markersize=1, color='grey')\n",
    "    ax.plot(robot_trajectory_list[i][:, 0], robot_trajectory_list[i][:, 1], \"o-\", markersize=3, color='red', label=\"Planned\")\n",
    "\n",
    "    if i < len(sqp_list) and j < len(sqp_list[i]):\n",
    "        planned_trajectory = sqp_list[i][j]\n",
    "        #ax.plot(planned_trajectory[:, 0], planned_trajectory[:, 1], \"o-\", markersize=3, color='green', alpha=0.4, label=f\"SQP iteration {j}\", label=f\"Sol {i}\")\n",
    "        ax.plot(\n",
    "        planned_trajectory[:, 0],\n",
    "        planned_trajectory[:, 1],\n",
    "        \"o-\",\n",
    "        markersize=3,\n",
    "        color='green',\n",
    "        alpha=0.4,\n",
    "        label=f\"Sol {i}, SQP {j}\"\n",
    "        )\n",
    "\n",
    "    ax.scatter(robot_trajectory[i:i+1, 0], robot_trajectory[i:i+1, 1], s=30, color='C100', label=\"Robot\")\n",
    "\n",
    "    x_center, y_center = float(CBF_object.center[0]), float(CBF_object.center[1])\n",
    "    half_length, half_width = float(CBF_object.length) / 2, float(CBF_object.width) / 2\n",
    "    ax.set_xlim(x_center - half_length, x_center + half_length)\n",
    "    ax.set_ylim(y_center - half_width, y_center + half_width)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(\"heading=%.2f velocity=%.2f\" % (robot_trajectory[i, 2], robot_trajectory[i, 3]))\n",
    "    ax.legend()\n",
    "\n",
    "    #ax = axs[1]\n",
    "    #ax.plot(robot_controls)\n",
    "    #ax.scatter([i], robot_controls[i:i+1, 0], label=\"$tan(\\\\delta)$\", color='C0')\n",
    "    #ax.scatter([i], robot_controls[i:i+1, 1], label=\"Acceleration\", color='C1')\n",
    "\n",
    "    #ax.hlines([steering_min, steering_max], 0, t-1, color='C0', linestyle='--')\n",
    "    #ax.hlines([acceleration_min, acceleration_max], 0, t-1, color='C1', linestyle='--')\n",
    "    #ax.plot(robot_trajectory[:, -1], markersize=3, color='C2')\n",
    "    #ax.scatter([i], robot_trajectory[i:i+1, 3], label=\"Velocity\", color='C2')\n",
    "    #ax.hlines([v_min, v_max], 0, t-1, color='C2', linestyle='--')\n",
    "\n",
    "    #ax.set_xlim([0, t])\n",
    "    #ax.set_ylim([-3, 3])\n",
    "    #ax.set_xlabel(\"Time step\")\n",
    "    #ax.set_ylabel(\"Control\")\n",
    "    #ax.set_title(\"Velocity, steering and acceleration\")\n",
    "    #ax.legend()\n",
    "    #ax.grid()\n",
    "\n",
    "total_frames = t * num_sqp_iterations\n",
    "ani = animation.FuncAnimation(fig, animate, frames=total_frames, interval=200)\n",
    "\n",
    "# Show animation\n",
    "plt.show()\n",
    "\n",
    "ani.save(\"robot_path_animation.mp4\", writer='ffmpeg', fps=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ME548",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
