{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tynan 548 Project File\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP X \n",
    "What this step does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cvxpy as cp # import cvxpy\n",
    "\n",
    "# in this problem, we will use the dynamaxsys library to import dynamical systems implemented in JAX: https://github.com/UW-CTRL/dynamaxsys\n",
    "from dynamaxsys.simplecar import DynamicallyExtendedSimpleCar\n",
    "from dynamaxsys.base import get_discrete_time_dynamics\n",
    "from dynamaxsys.utils import linearize\n",
    "\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import functools\n",
    "from ipywidgets import interact\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following segment involves the rover going from the starting point to the first sampling location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the robot dynamics\n",
    "wheelbase = 1.0\n",
    "dt = 0.1\n",
    "ct_robot_dynamics = DynamicallyExtendedSimpleCar(wheelbase=wheelbase) # robot dynamics\n",
    "dt_robot_dynamics = get_discrete_time_dynamics(ct_robot_dynamics, dt=dt) # discrete time dynamics\n",
    "state_dim = dt_robot_dynamics.state_dim\n",
    "control_dim = dt_robot_dynamics.control_dim\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definite Polygon shapes\n",
    "def convex_poly_constraint(state, polygon):\n",
    "    # Half-space representation: (x - p0) dot n ≥ 0 for each edge normal n\n",
    "    pos = state[:2]\n",
    "    n = polygon.shape[0]\n",
    "    constraints = []\n",
    "    for i in range(n):\n",
    "        p0 = polygon[i]\n",
    "        p1 = polygon[(i + 1) % n]\n",
    "        edge = p1 - p0\n",
    "        normal = jnp.array([-edge[1], edge[0]])  # outward normal\n",
    "        normal = normal / (jnp.linalg.norm(normal) + 1e-8)\n",
    "        constraints.append(jnp.dot(pos - p0, normal))\n",
    "    return jnp.min(jnp.stack(constraints)) #- robot_radius  # outer margin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the problem parameters\n",
    "planning_horizon = 25 # length of the planning horizon\n",
    "num_time_steps = 50 # number of time steps to simulate\n",
    "num_sqp_iterations = 15 # number of SQP iterations\n",
    "t = 0. # this doesn't affect anything, but a value is needed \n",
    "\n",
    "# control and velocity limits\n",
    "v_max = 1.5\n",
    "v_min = 0.\n",
    "acceleration_max = 1.0\n",
    "acceleration_min = -1.0\n",
    "steering_max = 0.5\n",
    "steering_min = -0.5\n",
    "\n",
    "# obstacle parameters\n",
    "obstacle_location = jnp.array([1.0, 0.0]) # obstacle location\n",
    "obstacle_location2 = jnp.array([3.0, -0.5]) # obstacle location\n",
    "obstacle_radius = 0.5 # obstacle radius\n",
    "robot_radius = 0.1 # robot radius\n",
    "goal_location = jnp.array([5.0, -0.5])\n",
    "goal_radius = 0.1\n",
    "\n",
    "polygon_crater = jnp.array([\n",
    "    [2.0, 0.0],\n",
    "    [2.2, 0.3],\n",
    "    [2.0, 0.6],\n",
    "    [1.8, 0.3]\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helper functions\n",
    "\n",
    "# define obstacle function g(x) >= 0\n",
    "# where g(x) is the distance from the obstacle\n",
    "@jax.jit\n",
    "def obstacle_constraint(state, obstacle, radius):\n",
    "    return jnp.linalg.norm(state[:2] - obstacle[:2]) - radius\n",
    "\n",
    "\n",
    "# define goal function g(x) >= 0\n",
    "# where g(x) is the distance from the goal\n",
    "\n",
    "@jax.jit\n",
    "def goal_constraint(state, goal, radius):\n",
    "    return jnp.linalg.norm(state[:2] - goal[:2]) - radius\n",
    "\n",
    "# function to simulate the discrete time dynamics given initial state and control sequence\n",
    "@functools.partial(jax.jit, static_argnames=[\"dt_dynamics\"])\n",
    "def simulate_discrete_time_dynamics(dt_dynamics, state, controls, t0, dt):\n",
    "    states = [state]\n",
    "    t = t0\n",
    "    for c in controls:\n",
    "\n",
    "        state = dt_dynamics(state, c, t)\n",
    "        states.append(state)\n",
    "        t += dt\n",
    "    return jnp.stack(states)\n",
    "\n",
    "# function to simulate the discrete time dynamics given initial state and control sequence\n",
    "# function slightly modified to add noise \n",
    "@functools.partial(jax.jit, static_argnames=[\"dt_dynamics\"])\n",
    "def simulate_discrete_time_dynamics_with_noise(dt_dynamics, state, controls, t0, dt, noises):\n",
    "    states = [state]\n",
    "    t = t0\n",
    "    for (c,noise) in zip(controls, noises):\n",
    "        state = dt_robot_dynamics(state, c, t) + noise * dt\n",
    "        states.append(state)\n",
    "        t += dt\n",
    "    return jnp.stack(states, -1)\n",
    "\n",
    "# jit the linearize constraint functions to make it run faster\n",
    "linearize_obstacle = jax.jit(jax.vmap(jax.grad(obstacle_constraint), in_axes=[0, None, None]))\n",
    "linearize_goal = jax.jit(jax.vmap(jax.grad(goal_constraint), in_axes=[0, None, None]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up cvxpy problem variables and parameters\n",
    "xs = cp.Variable([planning_horizon+1, state_dim])  # cvx variable for states\n",
    "us = cp.Variable([planning_horizon, control_dim])  # cvx variable for controls\n",
    "slack = cp.Variable(1) # slack variable to make sure the problem is feasible\n",
    "As = [cp.Parameter([state_dim, state_dim]) for _ in range(planning_horizon)]  # parameters for linearized dynamics\n",
    "Bs = [cp.Parameter([state_dim, control_dim]) for _ in range(planning_horizon)] # parameters for linearized dynamics\n",
    "Cs = [cp.Parameter([state_dim]) for _ in range(planning_horizon)] # parameters for linearized dynamics\n",
    "\n",
    "Gs = [cp.Parameter([state_dim]) for _ in range(planning_horizon+1)] # parameters for linearized constraints\n",
    "hs = [cp.Parameter(1) for _ in range(planning_horizon+1)] # parameters for linearized constraints\n",
    "Gs2 = [cp.Parameter([state_dim]) for _ in range(planning_horizon+1)] # parameters for linearized constraints\n",
    "hs2 = [cp.Parameter(1) for _ in range(planning_horizon+1)] # parameters for linearized constraints\n",
    "\n",
    "Goal_Gs = [cp.Parameter([state_dim]) for _ in range(planning_horizon+1)] # parameters for linearized constraints\n",
    "Goal_hs = [cp.Parameter(1) for _ in range(planning_horizon+1)] # parameters for linearized constraints\n",
    "\n",
    "xs_previous = cp.Parameter([planning_horizon+1, state_dim]) # parameter for previous solution\n",
    "us_previous = cp.Parameter([planning_horizon, control_dim]) # parameter for previous solution\n",
    "initial_state = cp.Parameter([state_dim]) # parameter for current robot state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up cvxpy problem cost and constraints\n",
    "beta1 = 0.2 # coefficient for control effort\n",
    "beta2 = 5. # coefficient for progress\n",
    "beta3 = 10. # coefficient for trust region\n",
    "slack_penalty = 1000. # coefficient for slack variable\n",
    "markup = 1.0\n",
    "goal_cost_weight = 1\n",
    "\n",
    "\n",
    "## removed objective beta2 * (xs[-1,2]**2 + xs[-1,1]**2 - xs[-1,0])\n",
    "objective = beta3 * (cp.sum_squares(xs - xs_previous) + cp.sum_squares(us - us_previous)) + slack_penalty * slack**2\n",
    "constraints = [xs[0] == initial_state, slack >= 0] # initial state and slack constraint\n",
    "for t in range(planning_horizon):\n",
    "\n",
    "    objective += (beta1 * cp.sum_squares(us[t]) ) * markup**t # only penalizes control effort\n",
    "    objective += goal_cost_weight * (cp.sum_squares((xs[t, :2] - goal_location)))*(1 + t/num_time_steps)  #.5 exponent, farther away, goal weight not as high\n",
    "\n",
    "    constraints += [xs[t+1] == As[t] @ xs[t] + Bs[t] @ us[t] + Cs[t]] # dynamics constraint\n",
    "    constraints += [xs[t,-1] <= v_max, xs[t,-1] >= v_min, us[t,1] <= acceleration_max, us[t,1] >= acceleration_min, us[t,0] <= steering_max, us[t,0] >= steering_min] # control and velocity limit constraints\n",
    "    constraints += [Gs[t] @ xs[t] + hs[t] >= -slack, Gs2[t] @ xs[t] + hs2[t] >= -slack] # linearized collision avoidance constraint\n",
    "constraints += [xs[planning_horizon,-1] <= v_max, xs[planning_horizon,-1] >= v_min, Gs[planning_horizon] @ xs[planning_horizon] + hs[planning_horizon] >= -slack, Gs2[planning_horizon] @ xs[planning_horizon] + hs2[planning_horizon] >= -slack] # constraints for last planning horizon step\n",
    "prob = cp.Problem(cp.Minimize(objective), constraints) # construct problem\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial states\n",
    "robot_state = jnp.array([-1.5, -0.5, 0., 1.])  # robot starting state\n",
    "robot_trajectory = [robot_state] # list to collect robot's state as it replans\n",
    "sqp_list = [] # list to collect each sqp iteration \n",
    "robot_control_list = []  # list to collect robot's constrols as it replans\n",
    "robot_trajectory_list = [] # list to collect robot's planned trajectories\n",
    "\n",
    "# initial robot planned state and controls\n",
    "previous_controls = jnp.zeros([planning_horizon, control_dim]) # initial guess for robot controls\n",
    "previous_states =  simulate_discrete_time_dynamics(dt_robot_dynamics, robot_state, previous_controls, 0., dt) # initial guess for robot states\n",
    "xs_previous.value = np.array(previous_states) # set xs_previous parameter value\n",
    "us_previous.value = np.array(previous_controls) # set us_previous parameter value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Replan at each timestep!\n",
    "Hopefully you saw from above the need to replan at each time step.\n",
    "Run the following cells and answer the question at the end.\n",
    "\n",
    "(Just run the cell below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial states\n",
    "robot_state = jnp.array([-1.5, -0.5, 0., 1.])  # robot starting state\n",
    "robot_trajectory = [robot_state] # list to collect robot's state as it replans\n",
    "sqp_list = [] # list to collect each sqp iteration \n",
    "robot_control_list = []  # list to collect robot's constrols as it replans\n",
    "robot_trajectory_list = [] # list to collect robot's planned trajectories\n",
    "\n",
    "# initial robot planned state and controls\n",
    "previous_controls = jnp.zeros([planning_horizon, control_dim]) # initial guess for robot controls\n",
    "previous_states =  simulate_discrete_time_dynamics(dt_robot_dynamics, robot_state, previous_controls, 0., dt) # initial guess for robot states\n",
    "xs_previous.value = np.array(previous_states) # set xs_previous parameter value\n",
    "us_previous.value = np.array(previous_controls) # set us_previous parameter value \n",
    "\n",
    "# precompute the noise\n",
    "key = jax.random.PRNGKey(0)\n",
    "noise_covar = jnp.diag(jnp.array([0.1, 0.1, 0.05, 0.2])) # noise covariance\n",
    "noises = jax.random.multivariate_normal(key, jnp.zeros(robot_state.shape), noise_covar, shape=(num_time_steps,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun the simulation, replanning at each time step, and adding some noise when computing the robot's next state.\n",
    "\n",
    "(Just run the cell below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = cp.CLARABEL\n",
    "\n",
    "for t in range(num_time_steps):\n",
    "    initial_state.value = np.array(robot_state)\n",
    "    sqp_solutions = [previous_states]\n",
    "    \n",
    "\n",
    "    \n",
    "    for i in range(num_sqp_iterations):\n",
    "        As_value, Bs_value, Cs_value = jax.vmap(linearize, in_axes=[None, 0, 0, None])(dt_robot_dynamics, previous_states[:-1], previous_controls, 0.)\n",
    "        Gs_value = linearize_obstacle(previous_states, obstacle_location, obstacle_radius + robot_radius) \n",
    "        hs_value = jax.vmap(obstacle_constraint, [0, None, None])(previous_states, obstacle_location, obstacle_radius + robot_radius) - jax.vmap(jnp.dot, [0, 0])(Gs_value, previous_states)\n",
    "        Gs2_value = linearize_obstacle(previous_states, obstacle_location2, obstacle_radius + robot_radius) \n",
    "        hs2_value = jax.vmap(obstacle_constraint, [0, None, None])(previous_states, obstacle_location2, obstacle_radius + robot_radius) - jax.vmap(jnp.dot, [0, 0])(Gs2_value, previous_states)\n",
    "        Goal_Gs_value = linearize_goal(previous_states, goal_location, goal_radius + robot_radius) \n",
    "        Goal_hs_value = jax.vmap(goal_constraint, [0, None, None])(previous_states, goal_location, goal_radius + robot_radius) - jax.vmap(jnp.dot, [0, 0])(Goal_Gs_value, previous_states)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(planning_horizon):\n",
    "            As[i].value = np.array(As_value[i])\n",
    "            Bs[i].value = np.array(Bs_value[i])\n",
    "            Cs[i].value = np.array(Cs_value[i])\n",
    "            Gs[i].value = np.array(Gs_value[i])\n",
    "            hs[i].value = np.array(hs_value[i:i+1])\n",
    "            Gs2[i].value = np.array(Gs2_value[i])\n",
    "            hs2[i].value = np.array(hs2_value[i:i+1])\n",
    "            Goal_Gs[i].value = np.array(Goal_Gs_value[i])\n",
    "            Goal_hs[i].value = np.array(Goal_hs_value[i:i+1])\n",
    "        Gs[planning_horizon].value = np.array(Gs_value[planning_horizon])\n",
    "        hs[planning_horizon].value = np.array(hs_value[planning_horizon:planning_horizon+1])\n",
    "        Gs2[planning_horizon].value = np.array(Gs2_value[planning_horizon])\n",
    "        hs2[planning_horizon].value = np.array(hs2_value[planning_horizon:planning_horizon+1])\n",
    "        Goal_Gs[planning_horizon].value = np.array(Gs_value[planning_horizon])\n",
    "        Goal_hs[planning_horizon].value = np.array(hs_value[planning_horizon:planning_horizon+1])\n",
    "        \n",
    "        result = prob.solve(solver=solver)\n",
    "\n",
    "        \n",
    "        if us.value is None:\n",
    "            print(\"No solution found\")\n",
    "            break\n",
    "        previous_controls = us.value\n",
    "        previous_states =  simulate_discrete_time_dynamics(dt_robot_dynamics, robot_state, previous_controls, 0., dt)\n",
    "        sqp_solutions.append(previous_states)\n",
    "        xs_previous.value = np.array(previous_states)\n",
    "        us_previous.value = np.array(previous_controls)\n",
    "    sqp_list.append(np.stack(sqp_solutions))\n",
    "    robot_control = previous_controls[0]\n",
    "    robot_control_list.append(robot_control)\n",
    "    \n",
    "    # get the robot next state using the control input\n",
    "    robot_state = dt_robot_dynamics(robot_state, robot_control, 0.) + noises[t] * dt\n",
    "    \n",
    "    # clipping the robot velocity so the problem doesn't become infeasible at the next step\n",
    "    robot_state = robot_state.at[3].set(jnp.clip(robot_state[3], v_min, v_max)) \n",
    "    \n",
    "    # add robot state and trajectory to the list\n",
    "    robot_trajectory.append(robot_state)\n",
    "    robot_trajectory_list.append(previous_states)\n",
    "    \n",
    "    # update the previous states and controls for the next iteration\n",
    "    previous_states =  simulate_discrete_time_dynamics(dt_robot_dynamics, robot_state, previous_controls, 0., dt)\n",
    "    \n",
    "    \n",
    "robot_trajectory = jnp.stack(robot_trajectory)\n",
    "robot_controls = jnp.stack(robot_control_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results!\n",
    "\n",
    "(Just run the cell below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf3ba278f2844708b78640ddac261e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=24, description='i', max=49), IntSlider(value=7, description='j', max=14…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the results. No need to add comments here. Just run this cell to visualize the results\n",
    "@interact(i=(0,num_time_steps-1), j=(0,num_sqp_iterations-1))\n",
    "def plot(i, j):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 4), gridspec_kw={'width_ratios': [2, 1]})\n",
    "    # fig, axs = plt.subplots(1,2, figsize=(10, 4))\n",
    "    ax = axs[0]\n",
    "    robot_position = robot_trajectory[i, :2]\n",
    "    print(\"test\",obstacle_location)\n",
    "    circle1 = plt.Circle(robot_position, robot_radius, color='C0', alpha=0.4)\n",
    "    circle2 = plt.Circle(obstacle_location, obstacle_radius, color='C1', alpha=0.4)\n",
    "    circle3 = plt.Circle(obstacle_location2, obstacle_radius, color='C1', alpha=0.4)\n",
    "    goal_loc = plt.Circle(goal_location, goal_radius, color='C2', alpha=0.6)\n",
    "    ax.add_patch(circle1)\n",
    "    ax.add_patch(circle2)\n",
    "    ax.add_patch(circle3)\n",
    "    ax.add_patch(goal_loc)\n",
    "    ax.plot(robot_trajectory[:,0], robot_trajectory[:,1], \"o-\", markersize=3, color='black')\n",
    "    ax.plot(robot_trajectory_list[i][:,0], robot_trajectory_list[i][:,1], \"o-\", markersize=3, color='red', label=\"Planned\")\n",
    "    # Plot planned trajectory for the selected SQP iteration\n",
    "    planned_trajectory = sqp_list[i][j]\n",
    "    ax.plot(planned_trajectory[:, 0], planned_trajectory[:, 1], \"o-\", markersize=3, color='green', alpha=0.4, label=\"SQP iteration %d\" % j)\n",
    "    ax.scatter(robot_trajectory[i:i+1,0], robot_trajectory[i:i+1,1], s=30,  color='C0', label=\"Robot\")\n",
    "    ax.set_xlim([-2, 7])\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    ax.axis(\"equal\")\n",
    "\n",
    "    ax.set_title(\"heading=%.2f velocity=%.2f\"%(robot_trajectory[i,2], robot_trajectory[i,3]))\n",
    "    \n",
    "    ax = axs[1]\n",
    "    ax.plot(robot_controls)\n",
    "    ax.scatter([i], robot_controls[i:i+1, 0], label=\"$tan(\\\\delta)$\", color='C0')\n",
    "    ax.scatter([i], robot_controls[i:i+1, 1], label=\"Acceleration\", color='C1')\n",
    "\n",
    "    ax.hlines(steering_min, 0, num_time_steps-1, color='C0', linestyle='--')\n",
    "    ax.hlines(steering_max, 0, num_time_steps-1, color='C0', linestyle='--')\n",
    "    ax.hlines(acceleration_min, 0, num_time_steps-1, color='C1', linestyle='--')\n",
    "    ax.hlines(acceleration_max, 0, num_time_steps-1, color='C1', linestyle='--')\n",
    "    \n",
    "    ax.plot(robot_trajectory[:,-1], markersize=3, color='C2')\n",
    "    ax.scatter([i], robot_trajectory[i:i+1, 3], label=\"Velocity\", color='C2')\n",
    "    ax.hlines(v_min, 0, num_time_steps-1, color='C2', linestyle='--')\n",
    "    ax.hlines(v_max, 0, num_time_steps-1, color='C2', linestyle='--')\n",
    "    ax.set_xlim([0, num_time_steps])\n",
    "    ax.set_ylim([-2, 2])\n",
    "    ax.set_xlabel(\"Time step\")\n",
    "    ax.set_ylabel(\"Control\")\n",
    "    ax.set_title(\"Velocity, steering and acceleration\")\n",
    "    ax.legend()\n",
    "    ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it guaranteed that your system will not hit the obstacle if we just apply MPC in the way we did above?\n",
    "If not, what are some techniques you could try to reduce the risk of colliding into the obstacles?\n",
    "\n",
    "(Optional) What if the obstacles were not stationary. But rather, they were moving. How would the problem change if the obstacle's motion were fully known (e.g., we knew exactly where the obstacle would be at any point in time), or if the obstacle's motion was uncertain (e.g., the obstacles were pedestrians, or space debris whose motion is not fully known). What are some techniques that could be applied to reduce the risk of collision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not guaranteed the system will not hit the obstacle. In my code, even with MPC applied, the first obstacle appears hit. In this case it was hit due to a sharp change in direction across only one timepoint. This indicates more safety measures should be put in place. Examples of those include increasing the size of the obstacle (similar to CBF applications) to compensate for error. While much more computationally intensive, the timestep frequency could be increased, which would make the magnitude of noise at each timestep smaller and give more opportunities for trajectory correction. Control restrictions can be put on the velocity to restrict movement, which also would give more opportunities for course correction. \n",
    "\n",
    "If the obstacles were moving but the motion was known, that should be able to be factored into the state and the problem should not change much. If the obstacle's motion was uncertain, then the planning horizon would need to be significantly decreased. A long planning horizon is useless if the states change unpredictably, and the desired trajectory may need to change on a whim. Adjusting the controls to allow for more leeway in sharp changes in acceleration would be helpful in dodging swift obstacles moving in the direction of the robot or its trajectory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ME548",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
