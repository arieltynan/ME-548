{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tynan 548 Project File\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP X \n",
    "What this step does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cvxpy as cp # import cvxpy\n",
    "\n",
    "# in this problem, we will use the dynamaxsys library to import dynamical systems implemented in JAX: https://github.com/UW-CTRL/dynamaxsys\n",
    "from dynamaxsys.simplecar import DynamicallyExtendedSimpleCar\n",
    "from dynamaxsys.base import get_discrete_time_dynamics\n",
    "from dynamaxsys.utils import linearize\n",
    "\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import numpy as np\n",
    "import functools\n",
    "from ipywidgets import interact\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following segment involves the rover going from the starting point to the first sampling location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the robot dynamics\n",
    "wheelbase = 1.0\n",
    "dt = 0.1\n",
    "ct_robot_dynamics = DynamicallyExtendedSimpleCar(wheelbase=wheelbase) # robot dynamics\n",
    "dt_robot_dynamics = get_discrete_time_dynamics(ct_robot_dynamics, dt=dt) # discrete time dynamics\n",
    "state_dim = dt_robot_dynamics.state_dim\n",
    "control_dim = dt_robot_dynamics.control_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the problem parameters\n",
    "planning_horizon = 20 # 20 # length of the planning horizon\n",
    "num_time_steps = 250 # number of time steps to simulate\n",
    "num_sqp_iterations = 5 # 15 # number of SQP iterations\n",
    "t = 0. # this doesn't affect anything, but a value is needed \n",
    "\n",
    "# control and velocity limits\n",
    "v_max = 2.0 #2\n",
    "v_min = 0.05 # 0.2\n",
    "acceleration_max = 2.0 #2/-2\n",
    "acceleration_min = -2.0\n",
    "steering_max = 1. #started 0.5/-0.5\n",
    "steering_min = -1.\n",
    "\n",
    "# obstacle parameters\n",
    "obstacle_location = jnp.array([1.0, 1.0]) # obstacle location\n",
    "obstacle_location2 = jnp.array([3.0, -0.5]) # obstacle location\n",
    "obstacle_radius = 0.5 # obstacle radius\n",
    "robot_radius = 0.1 # robot radius\n",
    "goal_locations = [jnp.array([3.5, 3.0]), jnp.array([3.5, 1.0]), jnp.array([5.5, 1.0]), jnp.array([2.0, -2.5]), jnp.array([0.0, 0.0]), jnp.array([2.0, 6.0]), jnp.array([-5.0, 6.5]), jnp.array([5.0, -4.0])]\n",
    "goal_location = goal_locations[0]\n",
    "goal_radius = 0.25\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Establish Rectangle Class ## \n",
    "\n",
    "class Rectangle:\n",
    "    def __init__(self, center, length, width, buffer=0.3): # 0.4 # 0.25 buffer makes robot go narrow way\n",
    "        \"\"\"\n",
    "        Initialize a rectangular obstacle.\n",
    "\n",
    "        Args:\n",
    "            center (tuple or jnp.ndarray): (x, y) coordinates of the center.\n",
    "            length (float): Length along the x-axis.\n",
    "            width (float): Width along the y-axis.\n",
    "            buffer (float): Optional buffer space for inflation.\n",
    "        \"\"\"\n",
    "        self.center = jnp.array(center)\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "        self.buffer = buffer\n",
    "\n",
    "    def inflated_half_lengths(self):\n",
    "        return (self.length / 2 + self.buffer, self.width / 2 + self.buffer)\n",
    "\n",
    "    def as_array(self):\n",
    "        \"\"\"Returns center and dimensions as a single array.\"\"\"\n",
    "        return jnp.array([*self.center, self.length, self.width, self.buffer])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Rectangle(center={self.center.tolist()}, l={self.length}, w={self.width}, buffer={self.buffer})\"\n",
    "\n",
    "\n",
    "rectangles = [\n",
    "    Rectangle(center=(2.0, 1.0), length=0.5, width=5.0),\n",
    "    Rectangle(center=(-2.0, 5.8), length=0.5, width=3.0),\n",
    "    Rectangle(center=(2.5, -1.0), length=2.0, width=0.5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS #\n",
    "\n",
    "# define obstacle function g(x) >= 0\n",
    "# where g(x) is the distance from the obstacle\n",
    "@jax.jit\n",
    "def obstacle_constraint(state, obstacle, radius):\n",
    "    return jnp.linalg.norm(state[:2] - obstacle[:2]) - radius\n",
    "\n",
    "\n",
    "def smooth_max(a, b, alpha=5.0):\n",
    "    return (1/alpha) * jnp.log(jnp.exp(alpha * a) + jnp.exp(alpha * b))\n",
    "\n",
    "@jax.jit\n",
    "def rect_constraint_smooth(state, obstacle, l, w, buffer, alpha=5.0):\n",
    "    dx = jnp.abs(state[0] - obstacle[0]) - l / 2 - buffer\n",
    "    dy = jnp.abs(state[1] - obstacle[1]) - w / 2 - buffer\n",
    "    return smooth_max(dx, dy, alpha=alpha)\n",
    "\n",
    "@jax.jit\n",
    "def smooth_rect_sdf(state, center, l, w, buffer, epsilon=1e-4):\n",
    "    \"\"\"Smoothed signed distance to a rectangle with rounded corners.\"\"\"\n",
    "    px = jnp.abs(state[0] - center[0]) - (l / 2 + buffer)\n",
    "    py = jnp.abs(state[1] - center[1]) - (w / 2 + buffer)\n",
    "\n",
    "    # Smooth SDF approximation: returns signed distance to edge/corner\n",
    "    dx = jnp.maximum(px, 0.0)\n",
    "    dy = jnp.maximum(py, 0.0)\n",
    "    outside_dist = jnp.sqrt(dx**2 + dy**2)\n",
    "\n",
    "    inside_dist = jnp.minimum(jnp.maximum(px, py), 0.0)\n",
    "\n",
    "    return outside_dist + inside_dist\n",
    "\n",
    "\n",
    "# define goal function g(x) >= 0\n",
    "# where g(x) is the distance from the goal\n",
    "\n",
    "@jax.jit\n",
    "def goal_constraint(state, goal, radius):\n",
    "    return jnp.linalg.norm(state[:2] - goal[:2]) - radius\n",
    "\n",
    "\n",
    "# function to simulate the discrete time dynamics given initial state and control sequence\n",
    "@functools.partial(jax.jit, static_argnames=[\"dt_dynamics\"])\n",
    "def simulate_discrete_time_dynamics(dt_dynamics, state, controls, t0, dt):\n",
    "    states = [state]\n",
    "    t = t0\n",
    "    for c in controls:\n",
    "\n",
    "        state = dt_dynamics(state, c, t)\n",
    "        states.append(state)\n",
    "        t += dt\n",
    "    return jnp.stack(states)\n",
    "\n",
    "# function to simulate the discrete time dynamics given initial state and control sequence\n",
    "# function slightly modified to add noise \n",
    "@functools.partial(jax.jit, static_argnames=[\"dt_dynamics\"])\n",
    "def simulate_discrete_time_dynamics_with_noise(dt_dynamics, state, controls, t0, dt, noises):\n",
    "    states = [state]\n",
    "    t = t0\n",
    "    for (c,noise) in zip(controls, noises):\n",
    "        state = dt_robot_dynamics(state, c, t + noise * dt) # take out noises for now\n",
    "        states.append(state)\n",
    "        t += dt\n",
    "    return jnp.stack(states, -1)\n",
    "\n",
    "# jit the linearize constraint functions to make it run faster\n",
    "linearize_obstacle = jax.jit(jax.vmap(jax.grad(obstacle_constraint), in_axes=[0, None, None]))\n",
    "linearize_goal = jax.jit(jax.vmap(jax.grad(goal_constraint), in_axes=[0, None, None]))\n",
    "linearize_rect_smooth = jax.jit(\n",
    "    jax.vmap(jax.grad(rect_constraint_smooth, argnums=0), in_axes=[0, None, None, None, None])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up cvxpy problem variables and parameters\n",
    "xs = cp.Variable([planning_horizon+1, state_dim])  # cvx variable for states\n",
    "us = cp.Variable([planning_horizon, control_dim])  # cvx variable for controls\n",
    "slack = cp.Variable(1) # slack variable to make sure the problem is feasible\n",
    "As = [cp.Parameter([state_dim, state_dim]) for _ in range(planning_horizon)]  # parameters for linearized dynamics\n",
    "Bs = [cp.Parameter([state_dim, control_dim]) for _ in range(planning_horizon)] # parameters for linearized dynamics\n",
    "Cs = [cp.Parameter([state_dim]) for _ in range(planning_horizon)] # parameters for linearized dynamics\n",
    "\n",
    "Gs = [cp.Parameter([state_dim]) for _ in range(planning_horizon+1)] # parameters for linearized constraints\n",
    "hs = [cp.Parameter(1) for _ in range(planning_horizon+1)] # parameters for linearized constraints\n",
    "#Gs_rect1 = [cp.Parameter([state_dim]) for _ in range(planning_horizon+1)] # parameters for linearized constraints\n",
    "#hs_rect1 = [cp.Parameter(1) for _ in range(planning_horizon+1)] # parameters for linearized constraints\n",
    "\n",
    "Gs_rects = [[cp.Parameter([state_dim]) for _ in range(planning_horizon + 1)] for _ in range(len(rectangles))]\n",
    "hs_rects = [[cp.Parameter(1) for _ in range(planning_horizon + 1)] for _ in range(len(rectangles))]\n",
    "\n",
    "\n",
    "Goal_Gs = [cp.Parameter([state_dim]) for _ in range(planning_horizon+1)] # parameters for linearized constraints\n",
    "Goal_hs = [cp.Parameter(1) for _ in range(planning_horizon+1)] # parameters for linearized constraints\n",
    "\n",
    "xs_previous = cp.Parameter([planning_horizon+1, state_dim]) # parameter for previous solution\n",
    "us_previous = cp.Parameter([planning_horizon, control_dim]) # parameter for previous solution\n",
    "initial_state = cp.Parameter([state_dim]) # parameter for current robot state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up cvxpy problem cost and constraints\n",
    "def construct_problem(goal_location):\n",
    "    beta1 = 0.2 # coefficient for control effort\n",
    "    beta2 = 5. # coefficient for progress\n",
    "    beta3 = 10. # coefficient for trust region\n",
    "    slack_penalty = 1000. # coefficient for slack variable\n",
    "    markup = 1.0\n",
    "    goal_cost_weight = 10. # 10\n",
    "    forward_velocity_weight = 0.1 # prev 0.1 # encourage robot to keep moving forward\n",
    "    v_min = 0.0\n",
    "    proximity_buffer = .4 # prox DISTANCE of robot to obstacles, soft discourage\n",
    "    proximity_weight = 1.\n",
    "\n",
    "    ## removed objective beta2 * (xs[-1,2]**2 + xs[-1,1]**2 - xs[-1,0])\n",
    "\n",
    "    # Discourages large changes in state and control\n",
    "    objective = beta3 * (cp.sum_squares(xs - xs_previous) + cp.sum_squares(us - us_previous)) + slack_penalty * slack**2\n",
    "\n",
    "    constraints = [xs[0] == initial_state, slack >= 0] # initial state and slack constraint\n",
    "    for t in range(planning_horizon):\n",
    "        objective += (beta1 * cp.sum_squares(us[t]) ) * markup**t # only penalizes control effort\n",
    "        #terminal_goal_dist_sq = cp.sum_squares(xs[planning_horizon, :2] - goal_location) * markup**t\n",
    "        #objective += terminal_goal_weight * terminal_goal_dist_sq\n",
    "\n",
    "\n",
    "            # NEW: Encourage steady progress toward the goal\n",
    "        step_goal_dist_sq = cp.sum_squares(xs[t, :2] - goal_location)\n",
    "        objective += goal_cost_weight * step_goal_dist_sq * markup**t\n",
    "        objective += -forward_velocity_weight * cp.sum(xs[:, 2]) * markup**t # encourages movement\n",
    "\n",
    "        constraints += [xs[t+1] == As[t] @ xs[t] + Bs[t] @ us[t] + Cs[t]] # dynamics constraint\n",
    "        constraints += [xs[t,-1] <= v_max, xs[t,-1] >= v_min, us[t,1] <= acceleration_max, us[t,1] >= acceleration_min, us[t,0] <= steering_max, us[t,0] >= steering_min] # control and velocity limit constraints\n",
    "        constraints += [Gs[t] @ xs[t] + hs[t] >= -slack] # linearized collision avoidance constraint for obstacles\n",
    "\n",
    "        # Penalize sharp changes in direction\n",
    "        #heading_diff = xs[t+1, 2] - xs[t, 2]\n",
    "        #objective += turning_penalty * cp.sum_squares(heading_diff)\n",
    "\n",
    "        for r_idx in range(len(Gs_rects)):\n",
    "            constraints += [Gs_rects[r_idx][t] @ xs[t] + hs_rects[r_idx][t] >= 0]\n",
    "            dist = Gs_rects[r_idx][t] @ xs[t] + hs_rects[r_idx][t]\n",
    "            # Penalty if within 1m of obstacle edge: (1 - dist)^2 if dist < 1\n",
    "            objective += proximity_weight * cp.pos(proximity_buffer - dist)**2\n",
    "\n",
    "\n",
    "    constraints += [xs[planning_horizon,-1] <= v_max, xs[planning_horizon,-1] >= v_min,\n",
    "                Gs[planning_horizon] @ xs[planning_horizon] + hs[planning_horizon] >= -slack]\n",
    "\n",
    "    for r_idx in range(len(Gs_rects)):\n",
    "        constraints += [Gs_rects[r_idx][planning_horizon] @ xs[planning_horizon] + hs_rects[r_idx][planning_horizon] >= -slack]\n",
    "\n",
    "    return cp.Problem(cp.Minimize(objective), constraints) # construct problem\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Replan at each timestep!\n",
    "Hopefully you saw from above the need to replan at each time step.\n",
    "Run the following cells and answer the question at the end.\n",
    "\n",
    "(Just run the cell below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial states\n",
    "robot_state = jnp.array([-1.5, -0.5, 0., 1.])  # robot starting state\n",
    "robot_trajectory = [robot_state] # list to collect robot's state as it replans\n",
    "sqp_list = [] # list to collect each sqp iteration \n",
    "robot_control_list = []  # list to collect robot's constrols as it replans\n",
    "robot_trajectory_list = [] # list to collect robot's planned trajectories\n",
    "\n",
    "# initial robot planned state and controls\n",
    "previous_controls = jnp.zeros([planning_horizon, control_dim]) # initial guess for robot controls\n",
    "previous_states =  simulate_discrete_time_dynamics(dt_robot_dynamics, robot_state, previous_controls, 0., dt) # initial guess for robot states\n",
    "xs_previous.value = np.array(previous_states) # set xs_previous parameter value\n",
    "us_previous.value = np.array(previous_controls) # set us_previous parameter value \n",
    "\n",
    "# precompute the noise\n",
    "key = jax.random.PRNGKey(0)\n",
    "noise_covar = jnp.diag(jnp.array([0.1, 0.1, 0.05, 0.2])) # noise covariance\n",
    "noises = jax.random.multivariate_normal(key, jnp.zeros(robot_state.shape), noise_covar, shape=(num_time_steps,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun the simulation, replanning at each time step, and adding some noise when computing the robot's next state.\n",
    "\n",
    "(Just run the cell below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No solution found\n",
      "Goal switched to: [3.5 1. ]\n",
      "Goal switched to: [5.5 1. ]\n",
      "Goal switched to: [ 2.  -2.5]\n",
      "Goal switched to: [0. 0.]\n",
      "Goal switched to: [2. 6.]\n",
      "Goal switched to: [-5.   6.5]\n",
      "No solution found\n",
      "Goal switched to: [ 5. -4.]\n",
      "No solution found\n"
     ]
    }
   ],
   "source": [
    "prob = construct_problem(goal_location)\n",
    "solver = cp.CLARABEL\n",
    "goal_index = 0\n",
    "for t in range(num_time_steps):\n",
    "    \n",
    "    goal_threshold = 0.2  # adjust threshold as needed\n",
    "    distance_to_goal = np.linalg.norm(robot_state[:2] - goal_location)\n",
    "    if distance_to_goal < goal_threshold:\n",
    "        goal_location = goal_locations[goal_index + 1]\n",
    "        goal_index += 1\n",
    "        print(f\"Goal switched to: {goal_location}\")\n",
    "\n",
    "        # Reset velocity\n",
    "        #robot_state = robot_state.at[-1].set(0)\n",
    "\n",
    "        # Reorient toward next goal\n",
    "        robot_control[:] = 0\n",
    "        delta = goal_location - robot_state[:2]\n",
    "        new_heading = np.arctan2(delta[1], delta[0])\n",
    "        robot_state = robot_state.at[2].set(new_heading)\n",
    "\n",
    "        prob = construct_problem(goal_location)  # rebuild with new goal\n",
    "        solver = cp.CLARABEL\n",
    "\n",
    "        previous_states = np.tile(np.array(robot_state), (planning_horizon + 1, 1))\n",
    "        previous_controls = np.zeros((planning_horizon, control_dim))\n",
    "    \n",
    "\n",
    "    \n",
    "    initial_state.value = np.array(robot_state)\n",
    "    sqp_solutions = [previous_states]\n",
    "\n",
    "    \n",
    "    for i in range(num_sqp_iterations):\n",
    "        #print(\"goal location in sqp loop:\", goal_location)\n",
    "        As_value, Bs_value, Cs_value = jax.vmap(linearize, in_axes=[None, 0, 0, None])(dt_robot_dynamics, previous_states[:-1], previous_controls, 0.)\n",
    "        Gs_value = linearize_obstacle(previous_states, obstacle_location, obstacle_radius + robot_radius) \n",
    "        hs_value = jax.vmap(obstacle_constraint, [0, None, None])(previous_states, obstacle_location, obstacle_radius + robot_radius) - jax.vmap(jnp.dot, [0, 0])(Gs_value, previous_states)\n",
    "    \n",
    "        # Init vectors for batch rectangle obstacles\n",
    "        Gs_rects_values = []\n",
    "        hs_rects_values = []\n",
    "\n",
    "        for rect in rectangles:\n",
    "            G_val = linearize_rect_smooth(previous_states, rect.center, rect.length, rect.width, rect.buffer)\n",
    "            h_val = (\n",
    "                jax.vmap(rect_constraint_smooth, [0, None, None, None, None])(previous_states, rect.center, rect.length, rect.width, rect.buffer)\n",
    "                - jax.vmap(jnp.dot, [0, 0])(G_val, previous_states)\n",
    "            )\n",
    "            Gs_rects_values.append(G_val)\n",
    "            hs_rects_values.append(h_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        Goal_Gs_value = linearize_goal(previous_states, goal_location, goal_radius + robot_radius) \n",
    "        Goal_hs_value = jax.vmap(goal_constraint, [0, None, None])(previous_states, goal_location, goal_radius + robot_radius) - jax.vmap(jnp.dot, [0, 0])(Goal_Gs_value, previous_states)\n",
    "\n",
    "        for i in range(planning_horizon):\n",
    "            As[i].value = np.array(As_value[i])\n",
    "            Bs[i].value = np.array(Bs_value[i])\n",
    "            Cs[i].value = np.array(Cs_value[i])\n",
    "            Gs[i].value = np.array(Gs_value[i])\n",
    "            hs[i].value = np.array(hs_value[i:i+1])\n",
    "\n",
    "            Goal_Gs[i].value = np.array(Goal_Gs_value[i])\n",
    "            Goal_hs[i].value = np.array(Goal_hs_value[i:i+1])\n",
    "\n",
    "                # Handle all rectangle constraints\n",
    "            for r_idx in range(len(rectangles)):\n",
    "                Gs_rects[r_idx][i].value = np.array(Gs_rects_values[r_idx][i])\n",
    "                hs_rects[r_idx][i].value = np.array(hs_rects_values[r_idx][i:i+1])\n",
    "\n",
    "\n",
    "        Gs[planning_horizon].value = np.array(Gs_value[planning_horizon])\n",
    "        hs[planning_horizon].value = np.array(hs_value[planning_horizon:planning_horizon+1])\n",
    "\n",
    "        Goal_Gs[planning_horizon].value = np.array(Goal_Gs_value[planning_horizon])\n",
    "        Goal_hs[planning_horizon].value = np.array(Goal_hs_value[planning_horizon:planning_horizon+1])\n",
    "\n",
    "        for r_idx in range(len(rectangles)):\n",
    "            Gs_rects[r_idx][planning_horizon].value = np.array(Gs_rects_values[r_idx][planning_horizon])\n",
    "            hs_rects[r_idx][planning_horizon].value = np.array(hs_rects_values[r_idx][planning_horizon:planning_horizon+1])\n",
    "\n",
    "\n",
    "\n",
    "        result = prob.solve(solver=solver)\n",
    "\n",
    "        if us.value is None:\n",
    "            print(\"No solution found\")\n",
    "            break\n",
    "\n",
    "        previous_controls = us.value\n",
    "        previous_states =  simulate_discrete_time_dynamics(dt_robot_dynamics, robot_state, previous_controls, 0., dt)\n",
    "        sqp_solutions.append(previous_states)\n",
    "        xs_previous.value = np.array(previous_states)\n",
    "        us_previous.value = np.array(previous_controls)\n",
    "\n",
    "    sqp_list.append(np.stack(sqp_solutions))\n",
    "    robot_control = previous_controls[0]\n",
    "    robot_control_list.append(robot_control)\n",
    "    \n",
    "    # get the robot next state using the control input\n",
    "    robot_state = dt_robot_dynamics(robot_state, robot_control, noises[t] * dt) \n",
    "    \n",
    "    # clipping the robot velocity so the problem doesn't become infeasible at the next step\n",
    "    robot_state = robot_state.at[3].set(jnp.clip(robot_state[3], v_min, v_max)) \n",
    "    \n",
    "    # add robot state and trajectory to the list\n",
    "    robot_trajectory.append(robot_state)\n",
    "    robot_trajectory_list.append(previous_states)\n",
    "    \n",
    "    # update the previous states and controls for the next iteration\n",
    "    previous_states =  simulate_discrete_time_dynamics(dt_robot_dynamics, robot_state, previous_controls, 0., dt)\n",
    "\n",
    "robot_trajectory = jnp.stack(robot_trajectory)\n",
    "robot_controls = jnp.stack(robot_control_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results!\n",
    "\n",
    "(Just run the cell below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f199c86643e24db2a640ce1dea0d1b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=124, description='i', max=249), IntSlider(value=2, description='j', max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_polygon_obstacle(polygon, ax):\n",
    "    polygon_loop = jnp.vstack([polygon, polygon[0]])\n",
    "    ax.plot(polygon_loop[:, 0], polygon_loop[:, 1], 'k-')\n",
    "    ax.fill(polygon_loop[:, 0], polygon_loop[:, 1], color='gray', alpha=0.5)\n",
    "\n",
    "# plotting the results. No need to add comments here. Just run this cell to visualize the results\n",
    "@interact(i=(0,num_time_steps-1), j=(0,num_sqp_iterations-1))\n",
    "\n",
    "def plot(i, j):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 4), gridspec_kw={'width_ratios': [2, 1]})\n",
    "    # fig, axs = plt.subplots(1,2, figsize=(10, 4))\n",
    "    ax = axs[0]\n",
    "    robot_position = robot_trajectory[i, :2]\n",
    "    circle1 = plt.Circle(robot_position, robot_radius, color='C0', alpha=0.4)\n",
    "    circle2 = plt.Circle(obstacle_location, obstacle_radius, color='C1', alpha=0.4)\n",
    "    #circle3 = plt.Circle(obstacle_location2, obstacle_radius, color='C1', alpha=0.4)\n",
    "    \n",
    "    # plot goals\n",
    "    for count in range(0, len(goal_locations)):\n",
    "        ax.add_patch(plt.Circle(goal_locations[count], goal_radius, color='C2', alpha=0.6))\n",
    "                \n",
    "        # Add goal index label at the center\n",
    "        ax.text(\n",
    "            goal_locations[count][0],                # x-coordinate\n",
    "            goal_locations[count][1],                # y-coordinate\n",
    "            str(count),                                 # text to display\n",
    "            color='black',                              # text color\n",
    "            fontsize=10,                                # size of the number\n",
    "            ha='center',                                # horizontal alignment\n",
    "            va='center',                                # vertical alignment\n",
    "            fontweight='bold'\n",
    "        )\n",
    "    \n",
    "    for count in range(0, len(rectangles)):\n",
    "        bottom_left = rectangles[count].center - jnp.array([rectangles[count].length / 2, rectangles[count].width / 2])\n",
    "        rect_plot = patches.Rectangle(\n",
    "            bottom_left,\n",
    "            rectangles[count].length,            # length along x\n",
    "            rectangles[count].width,            # width along y\n",
    "            linewidth=1,\n",
    "            edgecolor='C1',\n",
    "            facecolor='C1',\n",
    "            alpha=0.4\n",
    "        )\n",
    "        ax.add_patch(rect_plot)\n",
    "\n",
    "        # Add rectangle index label at the center\n",
    "        ax.text(\n",
    "            rectangles[count].center[0],                # x-coordinate\n",
    "            rectangles[count].center[1],                # y-coordinate\n",
    "            str(count),                                 # text to display\n",
    "            color='black',                              # text color\n",
    "            fontsize=10,                                # size of the number\n",
    "            ha='center',                                # horizontal alignment\n",
    "            va='center',                                # vertical alignment\n",
    "            fontweight='bold'\n",
    "        )\n",
    "\n",
    "    ax.add_patch(circle1)\n",
    "    ax.add_patch(circle2)\n",
    "    #ax.add_patch(circle3)\n",
    "    #plot_polygon_obstacle(polygon, ax)\n",
    "    ax.plot(robot_trajectory[:,0], robot_trajectory[:,1], \"o-\", markersize=3, color='grey')\n",
    "    ax.plot(robot_trajectory_list[i][:,0], robot_trajectory_list[i][:,1], \"o-\", markersize=3, color='red', label=\"Planned\")\n",
    "    # Plot planned trajectory for the selected SQP iteration\n",
    "\n",
    "    #planned_trajectory = sqp_list[i][j]\n",
    "\n",
    "    if i < len(sqp_list) and j < len(sqp_list[i]):\n",
    "        planned_trajectory = sqp_list[i][j]\n",
    "        ax.plot(planned_trajectory[:, 0], planned_trajectory[:, 1], \"o-\", markersize=3, color='green', alpha=0.4, label=f\"SQP iteration {j}\")\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, f\"No SQP {j} at step {i}\", transform=ax.transAxes, ha='center', va='center', fontsize=12, color='red')\n",
    "\n",
    "    #ax.plot(planned_trajectory[:, 0], planned_trajectory[:, 1], \"o-\", markersize=3, color='green', alpha=0.4, label=\"SQP iteration %d\" % j)\n",
    "    ax.scatter(robot_trajectory[i:i+1,0], robot_trajectory[i:i+1,1], s=30,  color='C100', label=\"Robot\")\n",
    "    ax.set_xlim([-2, 7])\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    ax.axis(\"equal\")\n",
    "\n",
    "    ax.set_title(\"heading=%.2f velocity=%.2f\"%(robot_trajectory[i,2], robot_trajectory[i,3]))\n",
    "    \n",
    "    ax = axs[1]\n",
    "    ax.plot(robot_controls)\n",
    "    ax.scatter([i], robot_controls[i:i+1, 0], label=\"$tan(\\\\delta)$\", color='C0')\n",
    "    ax.scatter([i], robot_controls[i:i+1, 1], label=\"Acceleration\", color='C1')\n",
    "\n",
    "    ax.hlines(steering_min, 0, num_time_steps-1, color='C0', linestyle='--')\n",
    "    ax.hlines(steering_max, 0, num_time_steps-1, color='C0', linestyle='--')\n",
    "    ax.hlines(acceleration_min, 0, num_time_steps-1, color='C1', linestyle='--')\n",
    "    ax.hlines(acceleration_max, 0, num_time_steps-1, color='C1', linestyle='--')\n",
    "    \n",
    "    ax.plot(robot_trajectory[:,-1], markersize=3, color='C2')\n",
    "    ax.scatter([i], robot_trajectory[i:i+1, 3], label=\"Velocity\", color='C2')\n",
    "    ax.hlines(v_min, 0, num_time_steps-1, color='C2', linestyle='--')\n",
    "    ax.hlines(v_max, 0, num_time_steps-1, color='C2', linestyle='--')\n",
    "    ax.set_xlim([0, num_time_steps])\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.set_xlabel(\"Time step\")\n",
    "    ax.set_ylabel(\"Control\")\n",
    "    ax.set_title(\"Velocity, steering and acceleration\")\n",
    "    ax.legend()\n",
    "    ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918920590dc34efe9e38659bbcefefea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=0, description='Timestep (i)', max=249), IntSlider(value=0, description='SQP it…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Prepare the figure and axes\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4), gridspec_kw={'width_ratios': [2, 1]})\n",
    "plt.close(fig)  # Don't display it immediately\n",
    "\n",
    "# Create a widget slider for time step i and SQP iteration j\n",
    "slider_i = widgets.IntSlider(min=0, max=num_time_steps-1, step=1, description='Timestep (i)')\n",
    "slider_j = widgets.IntSlider(min=0, max=num_sqp_iterations-1, step=1, description='SQP iter (j)')\n",
    "\n",
    "# Interactive update function\n",
    "def update_plot(i, j):\n",
    "    axs[0].clear()\n",
    "    axs[1].clear()\n",
    "    \n",
    "    ax = axs[0]\n",
    "    robot_position = robot_trajectory[i, :2]\n",
    "    circle1 = plt.Circle(robot_position, robot_radius, color='C0', alpha=0.4)\n",
    "    circle2 = plt.Circle(obstacle_location, obstacle_radius, color='C1', alpha=0.4)\n",
    "\n",
    "    for count in range(0, len(goal_locations)):\n",
    "        ax.add_patch(plt.Circle(goal_locations[count], goal_radius, color='C2', alpha=0.6))\n",
    "        ax.text(goal_locations[count][0], goal_locations[count][1], str(count),\n",
    "                color='black', fontsize=10, ha='center', va='center', fontweight='bold')\n",
    "\n",
    "    for count in range(0, len(rectangles)):\n",
    "        bottom_left = rectangles[count].center - jnp.array([rectangles[count].length / 2, rectangles[count].width / 2])\n",
    "        rect_plot = plt.Rectangle(bottom_left, rectangles[count].length, rectangles[count].width,\n",
    "                                  linewidth=1, edgecolor='C1', facecolor='C1', alpha=0.4)\n",
    "        ax.add_patch(rect_plot)\n",
    "        ax.text(rectangles[count].center[0], rectangles[count].center[1], str(count),\n",
    "                color='black', fontsize=10, ha='center', va='center', fontweight='bold')\n",
    "\n",
    "    ax.add_patch(circle1)\n",
    "    ax.add_patch(circle2)\n",
    "    ax.plot(robot_trajectory[:, 0], robot_trajectory[:, 1], \"o-\", markersize=3, color='grey')\n",
    "    ax.plot(robot_trajectory_list[i][:, 0], robot_trajectory_list[i][:, 1], \"o-\", markersize=3, color='red', label=\"Planned\")\n",
    "\n",
    "    if i < len(sqp_list) and j < len(sqp_list[i]):\n",
    "        planned_trajectory = sqp_list[i][j]\n",
    "        ax.plot(planned_trajectory[:, 0], planned_trajectory[:, 1], \"o-\", markersize=3,\n",
    "                color='green', alpha=0.4, label=f\"SQP iteration {j}\")\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, f\"No SQP {j} at step {i}\", transform=ax.transAxes,\n",
    "                ha='center', va='center', fontsize=12, color='red')\n",
    "\n",
    "    ax.scatter(robot_trajectory[i:i+1, 0], robot_trajectory[i:i+1, 1], s=30, color='C100', label=\"Robot\")\n",
    "    ax.set_xlim([-2, 7])\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    ax.axis(\"equal\")\n",
    "    ax.set_title(f\"heading={robot_trajectory[i, 2]:.2f} velocity={robot_trajectory[i, 3]:.2f}\")\n",
    "\n",
    "    # Controls plot\n",
    "    ax = axs[1]\n",
    "    ax.plot(robot_controls)\n",
    "    ax.scatter([i], robot_controls[i:i+1, 0], label=\"$tan(\\\\delta)$\", color='C0')\n",
    "    ax.scatter([i], robot_controls[i:i+1, 1], label=\"Acceleration\", color='C1')\n",
    "    ax.hlines([steering_min, steering_max], 0, num_time_steps-1, color='C0', linestyle='--')\n",
    "    ax.hlines([acceleration_min, acceleration_max], 0, num_time_steps-1, color='C1', linestyle='--')\n",
    "    ax.plot(robot_trajectory[:, -1], markersize=3, color='C2')\n",
    "    ax.scatter([i], robot_trajectory[i:i+1, 3], label=\"Velocity\", color='C2')\n",
    "    ax.hlines([v_min, v_max], 0, num_time_steps-1, color='C2', linestyle='--')\n",
    "    ax.set_xlim([0, num_time_steps])\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.set_xlabel(\"Time step\")\n",
    "    ax.set_ylabel(\"Control\")\n",
    "    ax.set_title(\"Velocity, steering and acceleration\")\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    display(fig)\n",
    "\n",
    "# Link sliders to plot update\n",
    "widgets.interactive_output(update_plot, {'i': slider_i, 'j': slider_j})\n",
    "\n",
    "# Display widgets\n",
    "display(widgets.HBox([slider_i, slider_j]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it guaranteed that your system will not hit the obstacle if we just apply MPC in the way we did above?\n",
    "If not, what are some techniques you could try to reduce the risk of colliding into the obstacles?\n",
    "\n",
    "(Optional) What if the obstacles were not stationary. But rather, they were moving. How would the problem change if the obstacle's motion were fully known (e.g., we knew exactly where the obstacle would be at any point in time), or if the obstacle's motion was uncertain (e.g., the obstacles were pedestrians, or space debris whose motion is not fully known). What are some techniques that could be applied to reduce the risk of collision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not guaranteed the system will not hit the obstacle. In my code, even with MPC applied, the first obstacle appears hit. In this case it was hit due to a sharp change in direction across only one timepoint. This indicates more safety measures should be put in place. Examples of those include increasing the size of the obstacle (similar to CBF applications) to compensate for error. While much more computationally intensive, the timestep frequency could be increased, which would make the magnitude of noise at each timestep smaller and give more opportunities for trajectory correction. Control restrictions can be put on the velocity to restrict movement, which also would give more opportunities for course correction. \n",
    "\n",
    "If the obstacles were moving but the motion was known, that should be able to be factored into the state and the problem should not change much. If the obstacle's motion was uncertain, then the planning horizon would need to be significantly decreased. A long planning horizon is useless if the states change unpredictably, and the desired trajectory may need to change on a whim. Adjusting the controls to allow for more leeway in sharp changes in acceleration would be helpful in dodging swift obstacles moving in the direction of the robot or its trajectory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ME548",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
