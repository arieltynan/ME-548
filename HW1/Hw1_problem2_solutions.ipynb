{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c7ce6a3",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "\n",
    "In this solution we will analyze the solution of problem 2 in assignment one. For each part of the exercise I will report: \n",
    "1. **Exercise Text:** Include the problem statement as in the original hw.\n",
    "2. **Implementation:** Write the necessary Python code.\n",
    "3. **Explanation:** Provide a thorough, explanation of each step, focusing on common errors.\n",
    "\n",
    "---------------------------------------\n",
    "\n",
    "\n",
    "We continue to consider the dynamically-extended unicycle model and investigate a way to linearize the dynamics around any state. \n",
    "First, we will perform the linearization analytically, and then leverage modern computation tools which will be incredibly helpful especially if the dynamics are complicated!\n",
    "We can efficiently compute gradients via automatic differentiation.\n",
    "JAX is an automatic differentiation library. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3470d4c",
   "metadata": {},
   "source": [
    "### (a) Linearize dynamics analytically\n",
    "Linearize the dynamics given in Problem 1 part (a) about a point $(\\mathbf{x}_0, \\mathbf{u}_0)$. That is, for linearized dynamics of the form $\\dot{\\mathbf{x}} \\approx A\\mathbf{x}+ B\\mathbf{u} + C$, give expressions for $A$, $B$, and $C$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac51793",
   "metadata": {},
   "source": [
    "### Solution \n",
    "\n",
    "We can start the problem defining:\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = \\begin{bmatrix}x \\\\\\\\ y \\\\\\\\ \\theta \\\\\\\\ v\\end{bmatrix},\\quad\n",
    "\\mathbf{u} = \\begin{bmatrix}\\omega \\\\\\\\ a\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x},\\mathbf{u}) =\n",
    "\\begin{bmatrix}\n",
    "v\\cos\\theta \\\\\\\\\n",
    "v\\sin\\theta \\\\\\\\\n",
    "\\omega \\\\\\\\\n",
    "a\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "In the vectors, we are representing the position $(x,y)$, the orientation $\\theta$, the linear speed $v$ and the two control inputs $\\omega$ (turn rate) and $a$ (forward acceleration).\n",
    "\n",
    "We can now make the following mathematical assumptions and simplifications:\n",
    "\n",
    "1. $\\dot{x} = v\\cos\\theta$  \n",
    "If you move forward at speed $v$ while pointing at angle $\\theta$, your horizontal velocity component is $v\\cos\\theta$.\n",
    "\n",
    "2. $\\dot{y} = v\\sin\\theta$  \n",
    "Similarly, the vertical velocity is $v\\sin\\theta$.\n",
    "\n",
    "3. $\\dot{\\theta} = \\omega$  \n",
    "The heading changes at the commanded turn rate $\\omega$.\n",
    "\n",
    "4. $\\dot{v} = a$  \n",
    "We assume the input $a$ directly controls the acceleration of the forward speed.\n",
    "\n",
    "Now, we want to derive the linear approximation:\n",
    "\n",
    "$$\n",
    "\\dot{\\mathbf{x}} \\approx A\\,\\mathbf{x} + B\\,\\mathbf{u} + C\n",
    "$$\n",
    "\n",
    "around an operating point $(\\mathbf{x}_0, \\mathbf{u}_0)$.\n",
    "\n",
    "The first step is to define the point of linearization:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_0 = \\begin{bmatrix}x_0 \\\\\\\\ y_0 \\\\\\\\ \\theta_0 \\\\\\\\ v_0\\end{bmatrix}, \\quad\n",
    "\\mathbf{u}_0 = \\begin{bmatrix}\\omega_0 \\\\\\\\ a_0\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "By the theory of linearized dynamical systems, we compute the Jacobian of $f$ with respect to $\\mathbf{x}$. In this way, we obtain the matrix $A$:\n",
    "\n",
    "$$\n",
    "A = \\left.\\frac{\\partial f}{\\partial \\mathbf{x}}\\right|_{(\\mathbf{x}_0,\\mathbf{u}_0)} =\n",
    "\\begin{bmatrix}\n",
    "0 & 0 & -v\\sin\\theta & \\cos\\theta \\\\\\\\\n",
    "0 & 0 &  v\\cos\\theta & \\sin\\theta \\\\\\\\\n",
    "0 & 0 &  0           & 0          \\\\\\\\\n",
    "0 & 0 &  0           & 0\n",
    "\\end{bmatrix}_{(\\mathbf{x}_0, \\mathbf{u}_0)}.\n",
    "$$\n",
    "\n",
    "The same can be done for $B$, by computing the Jacobian of $f$ with respect to $\\mathbf{u}$:\n",
    "\n",
    "$$\n",
    "B = \\left.\\frac{\\partial f}{\\partial \\mathbf{u}}\\right|_{(\\mathbf{x}_0,\\mathbf{u}_0)} =\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\\\\\n",
    "0 & 0 \\\\\\\\\n",
    "1 & 0 \\\\\\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "At this point, to calculate $C$, we can write down the matching condition:\n",
    "\n",
    "$$\n",
    "A\\,\\mathbf{x}_0 + B\\,\\mathbf{u}_0 + C = f(\\mathbf{x}_0,\\mathbf{u}_0),\n",
    "$$\n",
    "\n",
    "so that the linear model exactly reproduces the nonlinear dynamics at the chosen point. We can now write:\n",
    "\n",
    "$$\n",
    "C = f(\\mathbf{x}_0,\\mathbf{u}_0) - A\\,\\mathbf{x}_0 - B\\,\\mathbf{u}_0,\n",
    "$$\n",
    "\n",
    "which corresponds to the expression for the vector $C$.\n",
    "\n",
    "The reason why $A$ and $B$ are defined as above is that, in the first-order Taylor expansion of $f$ around $(\\mathbf{x}_0,\\mathbf{u}_0)$,\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}_0 + \\Delta x,\\, \\mathbf{u}_0 + \\Delta u)\n",
    "\\approx f(\\mathbf{x}_0,\\mathbf{u}_0)\n",
    "+ \\underbrace{\\frac{\\partial f}{\\partial \\mathbf{x}}}_{A}\\,\\Delta x\n",
    "+ \\underbrace{\\frac{\\partial f}{\\partial \\mathbf{u}}}_{B}\\,\\Delta u,\n",
    "$$\n",
    "\n",
    "the matrices of partial derivatives naturally capture how small perturbations $\\Delta x$ and $\\Delta u$ influence the time derivative $\\dot{\\mathbf{x}}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879c5457",
   "metadata": {},
   "source": [
    "### (a) CODE IMPLEMENTATION\n",
    "\n",
    "Let's start with importing the necessary packages to solve the exercise. Those are standard for everyone and they come from the different python libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9deb62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "from typing import Callable\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jacrev\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import functools\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0530ae7f",
   "metadata": {},
   "source": [
    "THe cell below contains some functions relative to exercise 1 of hw1 that will be necessary to run the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "750037ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Dynamics(metaclass=abc.ABCMeta):\n",
    "    dynamics_func: Callable\n",
    "    state_dim: int\n",
    "    control_dim: int\n",
    "\n",
    "    def __init__(self, dynamics_func, state_dim, control_dim):\n",
    "        self.dynamics_func = dynamics_func\n",
    "        self.state_dim = state_dim\n",
    "        self.control_dim = control_dim\n",
    "\n",
    "    def __call__(self, state, control, time=0):\n",
    "        return self.dynamics_func(state, control, time)\n",
    "    \n",
    "def dynamic_unicycle_ode(state, control, time):\n",
    "    x = state[0]\n",
    "    y = state[1]\n",
    "    theta = state[2]\n",
    "    v = state[3]\n",
    "    omega = control[0]\n",
    "    a = control[1]\n",
    "    dx = v*jnp.cos(theta)\n",
    "    dy = v*jnp.sin(theta)\n",
    "    dtheta = omega\n",
    "    dv = a \n",
    "    return jnp.array([dx, dy,dtheta,dv])\n",
    "\n",
    "\n",
    "state_dim = 4\n",
    "control_dim = 2\n",
    "continuous_dynamics = Dynamics(dynamic_unicycle_ode, state_dim, control_dim)\n",
    "\n",
    "def euler_integrate(dynamics, dt):\n",
    "    # zero-order hold\n",
    "    def integrator(x, u, t):\n",
    "        derivative = dynamics(x, u, t)\n",
    "        new_state = x+ dt*derivative\n",
    "        return new_state\n",
    "    return integrator\n",
    "\n",
    "def runge_kutta_integrator(dynamics, dt=0.1):\n",
    "    # zero-order hold\n",
    "    def integrator(x, u, t):\n",
    "        k1 = dynamics(x, u, t)\n",
    "        k2= dynamics(x+ 0.5*dt*k1, u, t)\n",
    "        k3 = dynamics(x+ 0.5*dt*k2, u, t)\n",
    "        k4 = dynamics(x+dt*k3, u, t)\n",
    "\n",
    "        return x+ dt/6*(k1 + 2*k2 + 2*k3 + k4) \n",
    "    return integrator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f7c07cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearize_unicycle_continuous_time_analytic(state, control, time):\n",
    "    '''\n",
    "    Linearizes the continuous time dynamics of the dynamic unicyle using analytic expression\n",
    "    Inputs:\n",
    "        state     : A jax.numpy array of size (n,)\n",
    "        control   : A jax.numpy array of size (m,)\n",
    "        time      : A real scalar\n",
    "\n",
    "    Outputs:\n",
    "        A : A jax.numpy array of size (n,n)\n",
    "        B : A jax.numpy array of size (n,m)\n",
    "        C : A jax.numpy array of size (n,1)\n",
    "    '''\n",
    "    theta = state[2]\n",
    "    v = state[3]\n",
    "    A = jnp.array([\n",
    "    [0, 0, -v*jnp.sin(theta), jnp.cos(theta)],\n",
    "    [0, 0,  v*jnp.cos(theta), jnp.sin(theta)],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0]\n",
    "    ])\n",
    "    B = jnp.array([\n",
    "    [0, 0],\n",
    "    [0, 0],\n",
    "    [1, 0],\n",
    "    [0, 1]\n",
    "    ])\n",
    "    f = dynamic_unicycle_ode(state, control, time)# this function comes from exercise (a) problem 1\n",
    "    C = f-A @ state - B@ control\n",
    "    C = C.reshape((4,1))\n",
    "    return A, B, C \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b4cfd0",
   "metadata": {},
   "source": [
    "\n",
    "Even if the theory above explains how the code is made, I can now puntualize some concept of the code, trying to solve every doubt that someone might have. \n",
    "\n",
    "Why do we use:\"theta = state[2]; v = state[3]??\n",
    "\n",
    "The state vector is defined as:\n",
    "$$\n",
    "\\mathbf{x} = \\begin{bmatrix}x,\\; y,\\; \\theta,\\; v\\end{bmatrix}^T,\n",
    "$$  \n",
    "so the indexing corresponds to:  \n",
    "- `state[0]` → $x$  \n",
    "- `state[1]` → $y$  \n",
    "- `state[2]` → $\\theta$, the heading angle  \n",
    "- `state[3]` → $v$, the forward velocity  \n",
    "\n",
    "This allow us extract theta and v from their correct positions to construct the matrix $A$.\n",
    "\n",
    "Why we use reshape on C??\n",
    "\n",
    "After computing  \n",
    "$$\n",
    "C = f - A\\,\\text{state} - B\\,\\text{control},\n",
    "$$  \n",
    "we obtain a NumPy array with shape (4,). By convention, and to avoid potential errors in matrix operations, it's better to reshape it into a column vector of shape (4, 1).  \n",
    "This \"reshape\" ensures that $C$ is always treated not as a row vector. By the way, the code works even if we dont't write this line. \n",
    "\n",
    "Why we use f = dynamic_unicycle_ode(state, control, time)???\n",
    "\n",
    "The function `dynamic_unicycle_ode` returns the actual vector of state derivatives at a given point. It is calculated and define in problem 1 part (a).\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}, \\mathbf{u}) =\n",
    "\\begin{bmatrix}\n",
    "v\\cos\\theta \\\\\\\\\n",
    "v\\sin\\theta \\\\\\\\\n",
    "\\omega \\\\\\\\\n",
    "a\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "This gives the exact nonlinear $\\dot{\\mathbf{x}}$ for the current $(\\mathbf{x}, \\mathbf{u})$.  \n",
    "Thanks to this we can calculate the matrix C as expalined before. \n",
    "\n",
    "Note: we could alternatively unpack omega = control[0] and a = control[1] and then define:\n",
    "\n",
    "C = jnp.array([\n",
    "    [v * jnp.cos(theta)],\n",
    "    [v * jnp.sin(theta)],\n",
    "    [omega],\n",
    "    [a]\n",
    "])\n",
    "\n",
    "I think that is more intuitive to do everything in terms of the nonlinear model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a20c3c",
   "metadata": {},
   "source": [
    "### (b) Evaluate linearized dynamics (analytic)\n",
    "Using your answer from 2(a), evaluate $A$, $B$, and $C$ for $\\mathbf{x}_0 = [0, 0, \\frac{\\pi}{4}, 2.]^T$ and $\\mathbf{u}_0 = [0.1, 1.]^T$. Give your answer to 2 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "852c635e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = [[ 0.    0.   -1.41  0.71]\n",
      " [ 0.    0.    1.41  0.71]\n",
      " [ 0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.  ]]\n",
      "B = [[0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 1]]\n",
      "C = [[ 1.11]\n",
      " [-1.11]\n",
      " [ 0.  ]\n",
      " [ 0.  ]]\n"
     ]
    }
   ],
   "source": [
    "x0 = jnp.array([0, 0, jnp.pi/4, 2])\n",
    "u0 = jnp.array([0.1, 1.0])\n",
    "time =0.0\n",
    "A,B,C = linearize_unicycle_continuous_time_analytic(x0, u0, time)\n",
    "print(\"A =\", jnp.round(A,2))\n",
    "print(\"B =\", jnp.round(B,2))\n",
    "print(\"C =\", jnp.round(C, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f35aaff",
   "metadata": {},
   "source": [
    "EXPLANATION: In this part we define the operating point vectors x0 and u0 as `jnp.array`,  \n",
    "and then call the previously defined function with time = 0. \n",
    "Calling the function linearize_unicycle_continuous_time_analutic we are ablke to \"extract\" the matrices A, B, C following the theoretical explenetion of the first steps. \n",
    "\n",
    "We also use `jnp.round` to round the results to two decimal places, as requested by the statement of the exercise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e381a0ae",
   "metadata": {},
   "source": [
    "### (c) Linearize dynamics using JAX autodiff\n",
    "Time to test out Jax's autodifferentiation capabilities! JAX has an [Autodiff Cookbook](https://docs.jax.dev/en/latest/notebooks/autodiff_cookbook.html) that provides more details about the various autodiff functions, forward vs backward autodiff, jacboians, hessians, and so forth. You are strongly encouraged read through it.\n",
    "\n",
    "Using Jax and its built-in `jax.jacobian` function, fill in the `linearize_autodiff` function that takes in a dynamics function, and a state and control to linearize about, and returns the $A$, $B$, and $C$ matrices describing the linearized dynamics. Test your function using the continuous-time dynamics with $\\mathbf{x}_0 = [0.0, 0.0, \\frac{\\pi}{4}, 2.0]^T$ and $\\mathbf{u}_0 = [0.1, 1.0]^T$ and use the provided test code to verify that the outputs you get from your function are the same as the values you get from `linearize_unicycle_continuous_time_analytic`.\n",
    "\n",
    "Side note for the curious: the `jnp.allclose` function tests if all corresponding elements of two arrays are within a small tolerance of each other. When working with finite-precision machine arithmetic, you can almost never test two numbers for exact equality directly, because different rounding errors in different computations very often result in very slightly different values even when the two calculations should theoretically result in the same number. For this reason, real numbers in software (which on almost all modern hardware are represented in [IEEE 754 floating-point format](https://en.wikipedia.org/wiki/IEEE_754)) are usually considered to be equal if they are close enough that their difference could be reasonably explained by rounding errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72d2473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearize_autodiff1(function_name, state, control, time):\n",
    "    '''\n",
    "    Linearizes the any dynamics using jax autodiff.\n",
    "    Inputs:\n",
    "        function_name: name of function to be linearized. Takes state, control, and time as inputs.\n",
    "        state     : A jax.numpy array of size (n,); the state to linearize about\n",
    "        control   : A jax.numpy array of size (m,); the control to linearize about\n",
    "        time      : A real scalar; the time to linearize about\n",
    "\n",
    "    Outputs:\n",
    "        A : A jax.numpy array of size (n,n)\n",
    "        B : A jax.numpy array of size (n,m)\n",
    "        C : A jax.numpy array of size (n,1)\n",
    "    '''\n",
    "\n",
    "    f1 = lambda x: function_name(x, control, time)\n",
    "    A = jacrev(f1)(state)\n",
    "\n",
    "    f2 = lambda u: function_name(state, u, time)\n",
    "    B = jacrev(f2)(control)\n",
    "    \n",
    "    f = function_name(state, control, time)\n",
    "\n",
    "    C = f -A@state -B@control.reshape((2,))\n",
    "    C = C.reshape((4, 1))\n",
    "\n",
    "\n",
    "    return A, B, C # update this line\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8298601",
   "metadata": {},
   "source": [
    "In this code, we build:\n",
    "\n",
    "1. f_x(x) = f(x, u₀, t₀), which is dependent only on the state x.\n",
    "2. f_u(u) = f(x₀, u, t₀), which is dependent only on the control u.\n",
    "\n",
    "We then call JAX’s `jax.jacobian`( )`jacrev`):\n",
    "\n",
    "- `A = jacrev(f_x)(x₀)` produces the full ∂f/∂x matrix at our linearization point.\n",
    "- `B = jacrev(f_u)(u₀)` produces the full ∂f/∂u matrix.\n",
    "\n",
    "Next, we evaluate: f0 = f(x₀, u₀, t₀) to form the term C = f_0 - A x - B u reshaped to a column vector to match the dimensions. \n",
    "\n",
    "In this way we know that the linearized model matches the nonlinear dynamics dot{x} ≈ A x + B u + C at the point we are considering, x0 and u0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bf2871",
   "metadata": {},
   "source": [
    "Below I report also another solution which might be more intuitive. The results are the exact same, it is just only another method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b3e4dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearize_autodiff2(function_name, state, control, time):\n",
    "    def dynamics_state(x):\n",
    "        return function_name(x, control, time)\n",
    "    def dynamics_control(u):\n",
    "        return function_name(state, u, time)\n",
    "\n",
    "    A = jax.jacobian(dynamics_state)(state)\n",
    "    B = jax.jacobian(dynamics_control)(control)\n",
    "\n",
    "    f0 = function_name(state, control, time)\n",
    "    C = (f0 - A @ state - B @ control).reshape(-1, 1)\n",
    "\n",
    "    return A, B, C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01e5e65",
   "metadata": {},
   "source": [
    "Let's now test the implementation. To have a correct implementation we should have True in all 3 the results. This means that the implementation using JAX autodiff has been done correctly, becaue it means that the matrix done with the linearized version matches the previos, standard version. I'm running both linearize_autoduff1 and linearize_autoduff2, provided above, to show that both can be used equally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17e23111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A matrices match: True\n",
      "B matrices match: True\n",
      "C matrices match: True\n",
      "A matrices match: True\n",
      "B matrices match: True\n",
      "C matrices match: True\n"
     ]
    }
   ],
   "source": [
    "# test code:\n",
    "state = jnp.array([0.0, 0.0, jnp.pi/4, 2.])\n",
    "control = jnp.array([0.1, 1.])\n",
    "time = 0.0\n",
    "\n",
    "A_autodiff1, B_autodiff1, C_autodiff1 = linearize_autodiff1(continuous_dynamics, state, control, time)\n",
    "A_autodiff2, B_autodiff2, C_autodiff2 = linearize_autodiff2(continuous_dynamics, state, control, time)\n",
    "A_analytic, B_analytic, C_analytic = linearize_unicycle_continuous_time_analytic(state, control, time)\n",
    "\n",
    "print('A matrices match:', jnp.allclose(A_autodiff1, A_analytic))\n",
    "print('B matrices match:', jnp.allclose(B_autodiff1, B_analytic))\n",
    "print('C matrices match:', jnp.allclose(C_autodiff1, C_analytic))\n",
    "print('A matrices match:', jnp.allclose(A_autodiff2, A_analytic))\n",
    "print('B matrices match:', jnp.allclose(B_autodiff2, B_analytic))\n",
    "print('C matrices match:', jnp.allclose(C_autodiff2, C_analytic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9498d68",
   "metadata": {},
   "source": [
    "### (d) Linearize discrete-time dynamics\n",
    "Assuming your answer from 2(c) matched 2(b) and that you are convinced of the power of automatic differentiation, use your `linearize_autodiff` function on `discrete_dynamics_euler` and `discrete_dynamics_rk` with $\\mathbf{x}_0 = [0.0, 0.0, \\frac{\\pi}{4}, 2.0]^T$ and $\\mathbf{u}_0 = [0.1, 1.0]^T$. (Imagine trying to differentiate the expressions analytically! It would be tedious!)\n",
    "\n",
    "Let $\\Delta t=0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de683c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_euler =\n",
      " [[ 1.    0.   -0.14  0.07]\n",
      " [ 0.    1.    0.14  0.07]\n",
      " [ 0.    0.    1.    0.  ]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "B_euler =\n",
      " [[0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.09999999 0.        ]\n",
      " [0.         0.09999999]]\n",
      "C_euler =\n",
      " [[ 0.11]\n",
      " [-0.11]\n",
      " [-0.  ]\n",
      " [-0.  ]]\n",
      "A_rk =\n",
      " [[ 1.          0.         -0.14999999  0.07      ]\n",
      " [ 0.          1.          0.14        0.07      ]\n",
      " [ 0.          0.          1.          0.        ]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "B_rk =\n",
      " [[-0.01        0.        ]\n",
      " [ 0.01        0.        ]\n",
      " [ 0.09999999  0.        ]\n",
      " [ 0.          0.09999999]]\n",
      "C_rk =\n",
      " [[ 0.12]\n",
      " [-0.11]\n",
      " [-0.  ]\n",
      " [-0.  ]]\n"
     ]
    }
   ],
   "source": [
    "x0 = jnp.array([0.0, 0.0, jnp.pi/4, 2.0])\n",
    "u0 = jnp.array([0.1, 1.0])\n",
    "dt = 0.1\n",
    "\n",
    "discrete_dynamics_euler = Dynamics(\n",
    "    euler_integrate(continuous_dynamics, dt), state_dim, control_dim\n",
    ")\n",
    "discrete_dynamics_rk = Dynamics(\n",
    "    runge_kutta_integrator(continuous_dynamics, dt), state_dim, control_dim\n",
    ")\n",
    "xse = linearize_autodiff1(discrete_dynamics_euler, x0, u0, dt)\n",
    "xsr = linearize_autodiff1(discrete_dynamics_rk, x0, u0, dt)\n",
    "\n",
    "A_e, B_e, C_e = xse\n",
    "A_r, B_r, C_r = xsr\n",
    "\n",
    "print(\"A_euler =\\n\", jnp.round(A_e, 2))\n",
    "print(\"B_euler =\\n\", jnp.round(B_e, 2))\n",
    "print(\"C_euler =\\n\", jnp.round(C_e, 2))\n",
    "print(\"A_rk =\\n\", jnp.round(A_r, 2))\n",
    "print(\"B_rk =\\n\", jnp.round(B_r, 2))\n",
    "print(\"C_rk =\\n\", jnp.round(C_r, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56162fb2",
   "metadata": {},
   "source": [
    "We applied our `linearize_autodiff` to two discrete time approximations of the unicycle model—Euler integration and 4th‐order Runge–Kutta. We used:\n",
    "$$\n",
    "x_0 = [0,\\;0,\\;\\tfrac{\\pi}{4},\\;2]^T,\\qquad\n",
    "u_0 = [0.1,\\;1.0]^T,\\qquad\\Delta t=0.1.\n",
    "$$\n",
    "The code can be seen with the following workflow: \n",
    "  1. defined `discrete_dynamics_euler` via `euler_integrate(continuous_dynamics, dt)` and `discrete_dynamics_rk` via `runge_kutta_integrator(continuous_dynamics, dt)`. The functions are taken from problem 1.   \n",
    "  2. Called `linearize_autodiff1()` to compute $A$, $B$, and $C$.  \n",
    "  3. Rounded all entries to two decimal places with `jnp.round` as asked in the exercise.\n",
    "\n",
    "As asked in the problem, dt = 0.1\n",
    "\n",
    "About the results we can say the following: \n",
    "- **Euler:** the system is approximated by taking a straight step using the initial slope. Since it's simpler, it should be less accurate.\n",
    "\n",
    "- **RK4:**  It looks at multiple slopes during the step, and it should give a more accurate linearization.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3a2d69",
   "metadata": {},
   "source": [
    "### (e) Applying `vmap` to linearize over multiple points\n",
    "Now, try to linearize your dynamics over multiple state-control values using `vmap`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b564e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A linearized has shape: (1000, 4, 4)\n",
      "B linearized has shape: (1000, 4, 2)\n",
      "C linearized has shape: (1000, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(42)  # Set a fixed seed\n",
    "n_samples = 1000\n",
    "state_dim = 4  # 4-dimensional state\n",
    "ctrl_dim = 2  # 2-dimensional control\n",
    "\n",
    "time = 0.0\n",
    "random_states = jax.random.normal(key, shape=(n_samples, state_dim))\n",
    "random_controls = jax.random.normal(key, shape=(n_samples, ctrl_dim))\n",
    "\n",
    "def linearize(x, u):\n",
    "    return linearize_autodiff1(discrete_dynamics_rk, x, u, time)\n",
    "\n",
    "lin = jax.vmap(linearize, in_axes=(0,0))\n",
    "Alin, Blin, Clin = lin(random_states, random_controls)\n",
    "\n",
    "print(\"A linearized has shape:\", Alin.shape)\n",
    "print(\"B linearized has shape:\", Blin.shape)\n",
    "print(\"C linearized has shape:\", Clin.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e144a21",
   "metadata": {},
   "source": [
    "We define the function `linearize(x, u)` to apply our `linearize_autodiff1` method to a single state–control pair $(x, u)$.  \n",
    "Specifically, the function `linearize(x, u)` follows the workflow:\n",
    "- Takes one pair of inputs,\n",
    "- Linearizes the discrete-time dynamics(using RK4 already shown above)\n",
    "- Returns matrices $A$, $B$, and $C$.\n",
    "\n",
    "Then, instead of calling this function manually 1000 times, we automize use:\n",
    "\n",
    "lin = jax.vmap(linearize, in_axes=(0, 0))\n",
    "Alin, Blin, Clin = lin(random_states, random_controls)\n",
    "\n",
    "Also:\n",
    "- 'jax.vmap' vectorizes the linearize function. We can see that as  applying that to each row of `random_states` and `random_controls`.  \n",
    "- `in_axes=(0, 0)` basically tells JAX to map over $x$ and $u$ inputs along their first axis (batch dimension).\n",
    "\n",
    "Running the cell we can also see that the output are the matrices A, B, C lizearized witht the shape corrisponding to respectively (1000, 4, 4), (1000, 4, 2) and (1000, 4, 1)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
