{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "### Instructions\n",
    "Download this jupyer notebook (button at the top of the page or download from the Github repository). Provide your answers as Markdown text, Python code, and/or produce plots as appropriate. The notebook should run all the cells in order without errors.  \n",
    "Submit both the `.ipynb` and a `.pdf` to Canvas.\n",
    "\n",
    "Make sure the `.pdf` has all the relevant outputs showing. To save as `.pdf` you can first export the notebook as `.html`, open it in a browers and then \"Print to PDF\". \n",
    "\n",
    "**NOTE:** As we will be sharing the files for peer grading, please keep your submission anonymous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (Stochastic dynamic programming)\n",
    "*(Adapted from Stanford AA 203)*\n",
    "\n",
    "In this problem we will explore discrete-time dynamic programming for stochastic systems; that is, systems where the result of taking a certain action is not deterministic, but instead any of a set of results may occur, according to some known probability distribution. In this case, we cannot optimize the value function directly, since even choosing a known sequence of actions will not always give in the same result. Instead, we optimize the [_expected value_](https://en.wikipedia.org/wiki/Expected_value) of the value function instead (if it's been a while since you've taken a probability class, or if you've never taken one, that Wikipedia article may be helpful).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Small hand-calculation problem\n",
    "\n",
    "Suppose we have a machine that is either running or is broken down. If it runs throughout one\n",
    "week, it makes a gross profit of \\$100. If it fails during the week, gross profit is zero. If it is running at the start of the week and we perform preventive maintenance, the probability that it will fail during the week is 0.4. If we do not perform such maintenance, the probability of failure is 0.7. However, maintenance will cost \\$20. If the machine is broken down at the start of the week, it may either be repaired at a cost of \\$40, in which case it will fail during the week with a probability\n",
    "of 0.4, or it may be replaced at a cost of \\$150 by a new machine; a new machine is guaranteed to run through its first week of operation. Using dynamic programming, find the optimal repair, replacement, and maintenance policy that maximizes total expected profit over four weeks, assuming a new machine at the start of the first week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Solutions here...]\n",
    "    \n",
    "**Week 4**: The expected profit at the start of week 4 given the following possible states:\n",
    "\n",
    "1. Running: \n",
    "   \n",
    "   If do nothing: Expected profit = 0.3 x 100 + 0.7 x 0 = 30\n",
    "   \n",
    "   If maintain: Expected profit = 0.6 (100 - 20) + 0.4 (-20) = 40\n",
    "   \n",
    "   Optimal: Maintain (V4 profit: 40 > 30)\n",
    "\n",
    "2. Broken:\n",
    "   \n",
    "   If repair: Expected profit = 0.6 (100) + 0 - 40 = 20\n",
    "   \n",
    "   If replace: Expected profit = 100 - 150 = -50\n",
    "   \n",
    "   Optimal: Repair (profit 20 > -50)\n",
    "\n",
    "**Week 3**: The expected profit at the start of week 3 given the following possible states:\n",
    "\n",
    "1. Running: \n",
    "   \n",
    "   If do nothing: \n",
    "      \n",
    "      Running: 0.3, Broken: 0.7\n",
    "      \n",
    "      Expected profit = 0.3 x ( 100 + V4(running) ) + 0.7 x ( 0 + V4(broken)) = 56\n",
    "   \n",
    "   If maintain: \n",
    "      \n",
    "      Running: 0.6, Broken: 0.4\n",
    "      \n",
    "      Expected profit = 0.6 (100 + 40) + 0.4 (0 + 20) - 20 = 72\n",
    "   \n",
    "   Optimal: Maintain (profit 72 > 56)\n",
    "\n",
    "2. Broken:\n",
    "   \n",
    "   If repair: \n",
    "      \n",
    "      Running: 0.6, Broken: 0.4\n",
    "      \n",
    "      Expected profit = 0.6 (100 + 40) + 0.4( 0 + 20) - 40 = 52\n",
    "   \n",
    "   If replace: Expected profit = 100 + 40 - 150 = -10\n",
    "  \n",
    "   Optimal: Repair (profit 52 > -10)\n",
    "\n",
    "**Week 2**: The expected profit at the start of week 2 given the following possible states:\n",
    "\n",
    "1. Running: \n",
    "   \n",
    "   If do nothing: \n",
    "      \n",
    "      Running: 0.3, Broken: 0.7\n",
    "      \n",
    "      Expected profit = 0.3 x ( 100 + 72 ) + 0.7 x ( 0 + 52) = 88\n",
    "   \n",
    "   If maintain: \n",
    "   \n",
    "      Running: 0.6, Broken: 0.4\n",
    "   \n",
    "      Expected profit = 0.6 (100 + 72 ) + 0.4 (0 + 52) - 20 = 104\n",
    "   \n",
    "   Optimal: Maintain (profit 104 > 88)\n",
    "\n",
    "2. Broken:\n",
    "   \n",
    "   If repair: \n",
    "   \n",
    "      Running: 0.6, Broken: 0.4\n",
    "   \n",
    "      Expected profit = 0.6 ( 100 + 72 ) + 0.4 ( 0 + 52 ) - 40 = 84\n",
    "   \n",
    "   If replace: Expected profit = 100 + 72 - 150 = 22\n",
    "   \n",
    "   Optimal: Repair (profit 84 > 22)\n",
    "\n",
    "**Week 1**: The expected profit at the start of week 3 given the following possible states as we have new machine guaranteed running without breaking:\n",
    "\n",
    "1. Running: \n",
    "\n",
    "   If do nothing: \n",
    "\n",
    "      Running: 1.0, Broken: 0.0\n",
    "\n",
    "      Expected profit = 1.0 x ( 100 + 104 ) + 0.0 x ( 0 + 84 ) = 204\n",
    "\n",
    "   If maintain: \n",
    "\n",
    "      Running: 1.0, Broken: 0.0\n",
    "\n",
    "      Expected profit = 1.0 (100 + 104 ) + 0.0 (0 + 84) - 20 = 184\n",
    "\n",
    "   Optimal: Do nothing (profit 204 > 184)\n",
    "\n",
    "**Optimal policy:**\n",
    "\n",
    "**Week 1**: As it will be running, do nothing.\n",
    "\n",
    "**Week 2-4**:\n",
    "\n",
    "Always maintain if running.\n",
    "\n",
    "Always repair if broken.\n",
    "\n",
    "Never replace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Larger system to solve by code\n",
    "\n",
    "Now we consider a more complicated system and a longer time horizon.\n",
    "\n",
    "Consider the same scenario as above, but with two additional machine states: overspeeding and destroyed. In the overspeeding state, the machine will with probability 0.5 produce \\$120 at the end of the week, but will otherwise be destroyed and produce no revenue for that week. If the machine is in the \"destroyed\" state at the start of a week, it may be replaced with a new machine for \\$150, the same as if it were broken down; otherwise it will produce no revenue for that week and remain in the destroyed state. A destroyed machine may not be repaired.\n",
    "\n",
    "Here are the state transitions possible in this new system:\n",
    "\n",
    "- If the machine is in the \"running\" state at the start of the week:\n",
    "    - If you do nothing (cost: \\$0)\n",
    "        - With probability 0.3 it will produce \\$100 and remain in the \"running\" state at the end of the week.\n",
    "        - With probabiity 0.63 it will produce \\$0 and enter the \"broken down\" state at the end of the week.\n",
    "        - With probability 0.07 it will produce \\$100 and enter the \"overspeeding\" state at the end of the week.\n",
    "    - If you maintain the machine (cost: \\$20):\n",
    "        - With probability 0.6 it will produce \\$100 and remain in the \"running\" state at the end of the week.\n",
    "        - With probabiity 0.37 it will produce \\$0 and enter the \"broken down\" state at the end of the week.\n",
    "        - With probability 0.03 it will produce \\$100 and enter the \"overspeeding\" state at the end of the week.\n",
    "- If the machine is in the \"broken down\" state at the start of the week:\n",
    "    - If you do nothing (cost: \\$0):\n",
    "        - The machine will produce \\$0, and will remain in the \"broken down\" state at the end of the week.\n",
    "    - If you repair the machine (cost: \\$40):\n",
    "        - With probability 0.6 it will produce \\$100 and remain in the \"running\" state at the end of the week.\n",
    "        - With probabiity 0.37 it will produce \\$0 and enter the \"broken down\" state at the end of the week.\n",
    "        - With probability 0.03 it will produce \\$100 and enter the \"overspeeding\" state at the end of the week.\n",
    "    - If you replace the machine (cost: \\$150):\n",
    "        - The new machine will produce \\$100 and be in the \"running\" state at the end of the week.\n",
    "- If the machine is in the \"overspeeding\" state at the start of the week:\n",
    "    - If you do nothing (cost: \\$0):\n",
    "        - With probability 0.5 it will produce \\$120 and remain in the \"overspeeding\" state at the end of the week.\n",
    "        - With probability 0.5 it will produce \\$0 and enter the \"destroyed\" state at the end of the week.\n",
    "    - If you repair the machine (cost: \\$40):\n",
    "        - With probability 0.6 it will produce \\$100 and remain in the \"running\" state at the end of the week.\n",
    "        - With probabiity 0.37 it will produce \\$0 and enter the \"broken down\" state at the end of the week.\n",
    "        - With probability 0.03 it will produce \\$100 and enter the \"overspeeding\" state at the end of the week.\n",
    "- If the machine is in the \"destroyed\" state at the start of the week:\n",
    "    - If you do nothing (cost: \\$0):\n",
    "        - The machine will produce \\$0 and remain in the \"destroyed\" state at the end of the week.\n",
    "    - If you replace the machine (cost: \\$150):\n",
    "        - The new machine will produce \\$100 and be in the \"running\" state at the end of the week.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Suppose that by the end of the 20th week (i.e., start of the 21st week), the machine is still \"running\", then you can sell the machine for \\$200. \n",
    "If the machine is \"overspeeding\", the machine will sell for \\$120.\n",
    "If the machine is \"broken down\", the machine will sell for \\$30.\n",
    "If the machine is \"destroyed\", then you must pay for a recycling fee of \\$50.\n",
    "\n",
    "In the following parts, you will implement the dynamic programming algorithm to find the optimal action to take in each state in each week, as well as the optimal expected profit in each state in each week. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)(i) Quick hand calculation\n",
    "Let's start by considering just the last week and computing the first dynamic programming step by hand.\n",
    "What is the value at the start of week 21? That is, what is the terminal value?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Solution here...]\n",
    "\n",
    "At the start of week 21, the terminal value is:\n",
    "\n",
    "**Running**: $200 (sell value)\n",
    "\n",
    "**Overspeeding**: $120 (sell value)\n",
    "\n",
    "**Broken down**: $30 (sell value)\n",
    "\n",
    "**Destroyed**: -$50 (recycling fee)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)(ii)\n",
    "Given that, what is the value at the start of week 20 and the corresponding optimal policy?    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Solution here...]\n",
    "\n",
    "Value at week 20 and optimal policy\n",
    "\n",
    "Let V21(state) be as above.\n",
    "\n",
    "For each state at week 20, computing the best expected value:\n",
    "\n",
    "1. Running:\n",
    "   \n",
    "   Do nothing (cost $0):\n",
    "   \n",
    "      Remain running: 0.3 × (100 + 200)\n",
    "   \n",
    "      Broken: 0.63 × (0 + 30)\n",
    "   \n",
    "      Overspeeding: 0.07 × (100 + 120)\n",
    "   \n",
    "      Expected value: 0.3 (300) + 0.63 (30) + 0.07 (220) = 124.3\n",
    "\n",
    "  Maintain (cost $20):\n",
    "\n",
    "  Remain running: 0.6 × (100 + 200)\n",
    "\n",
    "  Broken: 0.37 × (0 + 30)\n",
    "\n",
    "  Overspeeding: 0.03 × (100 + 120)\n",
    "\n",
    "  Expected value: 0.6 ( 300 ) + 0.37 (30) + 0.03 (220) - 20 = 177.7\n",
    "\n",
    "  Optimal: Maintain (177.7 > 124.3)\n",
    "\n",
    "..............................................................\n",
    "\n",
    "1. Broken:\n",
    "\n",
    "Do nothing: 0 + 30 = 30\n",
    "\n",
    "Repair (cost $40):\n",
    "\n",
    "Remain running: 0.6 × (100 + 200)\n",
    "\n",
    "Broken: 0.37 × (0 + 30)\n",
    "\n",
    "Overspeeding: 0.03 × (100 + 120)\n",
    "\n",
    "Expected value: 0.6×300 + 0.37×30 + 0.03×220 − 40 = 157.7\n",
    "\n",
    "Replace (cost $150): 100 + 200 - 150 = 150\n",
    "\n",
    "Optimal: Repair (157.7 > 150 > 30)\n",
    "\n",
    ".............................................................\n",
    "\n",
    "3. Overspeeding:\n",
    "\n",
    "Do nothing (cost $0):\n",
    "\n",
    "0.5 × (120 + 120) + 0.5 × (0 - 50) = 0.5 × 240 + 0.5 × (-50) = 120 - 25 = 95\n",
    "\n",
    "Repair (cost $40):\n",
    "\n",
    "Remain running: 0.6 × (100 + 200)\n",
    "\n",
    "Broken: 0.37 × (0 + 30)\n",
    "\n",
    "Overspeeding: 0.03 × (100 + 120)\n",
    "\n",
    "Expected value: 0.6×300+0.37×30+0.03×220−40=180+11.1+6.6−40=157.7\n",
    "\n",
    "Optimal: Repair (157.7 > 95)\n",
    "\n",
    "............................................................\n",
    "\n",
    "4. Destroyed:\n",
    "\n",
    "Do nothing: -50\n",
    "\n",
    "Replace: 100 + 200 - 150 = 150\n",
    "\n",
    "Optimal: Replace (150 > -50)\n",
    "\n",
    "............................................................\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)(iii)\n",
    "\n",
    "Now, fill in the following functions to compute the value function and optimal policy over the 20 weeks.\n",
    "\n",
    "Print out the optimal policy and value function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the states and actions of the system, and corresponding index \n",
    "STATES = {\"RUNNING\": 0, \"BROKEN_DOWN\": 1, \"OVERSPEEDING\": 2, \"DESTROYED\": 3}\n",
    "ACTIONS = {\"NOTHING\": 0, \"MAINTAIN\": 1, \"REPAIR\": 2, \"REPLACE\": 3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_transition_probability_matrix(STATES, ACTIONS):\n",
    "    \"\"\"\n",
    "    Construct the transition probability matrix for the car maintenance problem.\n",
    "    The transition probability matrix is a 3D array where the first dimension\n",
    "    represents the current state, the second dimension represents the next state,\n",
    "    and the third dimension represents the action taken.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the transition probability matrix\n",
    "    n_states = len(STATES)\n",
    "    n_actions = len(ACTIONS)\n",
    "    P = np.zeros((n_states, n_states, n_actions))\n",
    "\n",
    "    # State: RUNNING, Allowable Actions: NOTHING, MAINTAIN\n",
    "    P[STATES[\"RUNNING\"], STATES[\"RUNNING\"], ACTIONS[\"NOTHING\"]] = 0.3\n",
    "    P[STATES[\"RUNNING\"], STATES[\"BROKEN_DOWN\"], ACTIONS[\"NOTHING\"]] = 0.63\n",
    "    P[STATES[\"RUNNING\"], STATES[\"OVERSPEEDING\"], ACTIONS[\"NOTHING\"]] = 0.07\n",
    "    P[STATES[\"RUNNING\"], STATES[\"RUNNING\"], ACTIONS[\"MAINTAIN\"]] = 0.6\n",
    "    P[STATES[\"RUNNING\"], STATES[\"BROKEN_DOWN\"], ACTIONS[\"MAINTAIN\"]] = 0.37\n",
    "    P[STATES[\"RUNNING\"], STATES[\"OVERSPEEDING\"], ACTIONS[\"MAINTAIN\"]] = 0.03\n",
    "\n",
    "    # State: BROKEN_DOWN, Allowable Actions: NOTHING, REPAIR, REPLACE\n",
    "    P[STATES[\"BROKEN_DOWN\"], STATES[\"BROKEN_DOWN\"], ACTIONS[\"NOTHING\"]] = 1.0\n",
    "    P[STATES[\"BROKEN_DOWN\"], STATES[\"RUNNING\"], ACTIONS[\"REPAIR\"]] = 0.6\n",
    "    P[STATES[\"BROKEN_DOWN\"], STATES[\"BROKEN_DOWN\"], ACTIONS[\"REPAIR\"]] = 0.37\n",
    "    P[STATES[\"BROKEN_DOWN\"], STATES[\"OVERSPEEDING\"], ACTIONS[\"REPAIR\"]] = 0.03\n",
    "    P[STATES[\"BROKEN_DOWN\"], STATES[\"RUNNING\"], ACTIONS[\"REPLACE\"]] = 1.0\n",
    "\n",
    "    # State: OVERSPEEDING, Allowable Actions: NOTHING, REPAIR\n",
    "    P[STATES[\"OVERSPEEDING\"], STATES[\"OVERSPEEDING\"], ACTIONS[\"NOTHING\"]] = 0.5\n",
    "    P[STATES[\"OVERSPEEDING\"], STATES[\"DESTROYED\"], ACTIONS[\"NOTHING\"]] = 0.5\n",
    "    P[STATES[\"OVERSPEEDING\"], STATES[\"RUNNING\"], ACTIONS[\"REPAIR\"]] = 0.6\n",
    "    P[STATES[\"OVERSPEEDING\"], STATES[\"BROKEN_DOWN\"], ACTIONS[\"REPAIR\"]] = 0.37\n",
    "    P[STATES[\"OVERSPEEDING\"], STATES[\"OVERSPEEDING\"], ACTIONS[\"REPAIR\"]] = 0.03\n",
    "\n",
    "    # State: DESTROYED, Allowable Actions: NOTHING, REPLACE\n",
    "    P[STATES[\"DESTROYED\"], STATES[\"DESTROYED\"], ACTIONS[\"NOTHING\"]] = 1.0\n",
    "    P[STATES[\"DESTROYED\"], STATES[\"RUNNING\"], ACTIONS[\"REPLACE\"]] = 1.0\n",
    "\n",
    "    return P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_reward_matrix(STATES, ACTIONS):\n",
    "    \"\"\"\n",
    "    Construct the reward matrix for the car maintenance problem.\n",
    "    The reward matrix is a 3D array where the first dimension\n",
    "    represents the current state, the second dimension represents the next state,\n",
    "    and the third dimension represents the action taken.\n",
    "    \"\"\" \n",
    "\n",
    "    # Initialize the reward matrix (dim(state) x dim(state) x dim(action))\n",
    "    n_states = len(STATES)\n",
    "    n_actions = len(ACTIONS)\n",
    "    R = np.full((n_states, n_actions), -np.inf)\n",
    "\n",
    "\n",
    "    # State: RUNNING (0), Allowable Actions: NOTHING, MAINTAIN\n",
    "    R[STATES[\"RUNNING\"], ACTIONS[\"NOTHING\"]] = 37\n",
    "    R[STATES[\"RUNNING\"], ACTIONS[\"MAINTAIN\"]] = 43\n",
    "\n",
    "    # State: BROKEN_DOWN (1), Allowable Actions: NOTHING, REPAIR, REPLACE\n",
    "    R[STATES[\"BROKEN_DOWN\"], ACTIONS[\"NOTHING\"]] = 0\n",
    "    R[STATES[\"BROKEN_DOWN\"], ACTIONS[\"REPAIR\"]] = 23\n",
    "    R[STATES[\"BROKEN_DOWN\"], ACTIONS[\"REPLACE\"]] = -50\n",
    "\n",
    "    # State: OVERSPEEDING (2), NOTHING, REPAIR\n",
    "    R[STATES[\"OVERSPEEDING\"], ACTIONS[\"NOTHING\"]] = 60\n",
    "    R[STATES[\"OVERSPEEDING\"], ACTIONS[\"REPAIR\"]] = 23\n",
    "\n",
    "    # State: DESTROYED (3), NOTHING, REPLACE\n",
    "    R[STATES[\"DESTROYED\"], ACTIONS[\"NOTHING\"]] = 0\n",
    "    R[STATES[\"DESTROYED\"], ACTIONS[\"REPLACE\"]] = -50\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allowable_action_set(state):\n",
    "    \"\"\"\n",
    "    Returns the set of actions that are allowed in the given state.\n",
    "    \"\"\"\n",
    "    if state == \"RUNNING\":\n",
    "        return [\"NOTHING\", \"MAINTAIN\"]\n",
    "    elif state == \"BROKEN_DOWN\":\n",
    "        return [\"NOTHING\", \"REPAIR\", \"REPLACE\"]\n",
    "    elif state == \"OVERSPEEDING\":\n",
    "        return [\"NOTHING\", \"REPAIR\"]\n",
    "    elif state == \"DESTROYED\":\n",
    "        return [\"NOTHING\", \"REPLACE\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RUNNING': 0, 'BROKEN_DOWN': 1, 'OVERSPEEDING': 2, 'DESTROYED': 3}\n",
      "Week 1,: ['MAINTAIN', 'REPAIR', 'REPAIR', 'REPLACE']\n",
      "Week 2,: ['MAINTAIN', 'REPAIR', 'REPAIR', 'REPLACE']\n",
      "Week 3,: ['MAINTAIN', 'REPAIR', 'REPAIR', 'REPLACE']\n",
      "Week 4,: ['MAINTAIN', 'REPAIR', 'REPAIR', 'REPLACE']\n",
      "Week 5,: ['MAINTAIN', 'REPAIR', 'REPAIR', 'REPLACE']\n",
      "Week 6,: ['MAINTAIN', 'REPAIR', 'REPAIR', 'REPLACE']\n",
      "Week 7,: ['MAINTAIN', 'REPAIR', 'REPAIR', 'REPLACE']\n",
      "Week 8,: ['MAINTAIN', 'REPAIR', 'REPAIR', 'REPLACE']\n",
      "Week 9,: ['MAINTAIN', 'REPAIR', 'REPAIR', 'REPLACE']\n",
      "Week 10,: ['MAINTAIN', 'REPAIR', 'REPAIR', 'REPLACE']\n",
      "Week 11,: ['MAINTAIN', 'REPAIR', 'REPAIR', 'REPLACE']\n",
      "Week 12,: ['MAINTAIN', 'REPAIR', 'REPAIR', 'REPLACE']\n",
      "Week 13,: ['MAINTAIN', 'REPAIR', 'REPAIR', 'REPLACE']\n",
      "Week 14,: ['MAINTAIN', 'REPAIR', 'REPAIR', 'REPLACE']\n",
      "Week 15,: ['MAINTAIN', 'REPAIR', 'REPAIR', 'REPLACE']\n",
      "Week 16,: ['MAINTAIN', 'REPAIR', 'REPAIR', 'REPLACE']\n",
      "Week 17,: ['MAINTAIN', 'REPAIR', 'REPAIR', 'REPLACE']\n",
      "Week 18,: ['MAINTAIN', 'REPAIR', 'NOTHING', 'REPLACE']\n",
      "Week 19,: ['MAINTAIN', 'REPAIR', 'NOTHING', 'NOTHING']\n",
      "Week 20,: ['MAINTAIN', 'REPAIR', 'REPAIR', 'REPLACE']\n",
      "Week 1,: [843.74, 823.74, 823.74, 758.74]\n",
      "Week 2,: [808.74, 788.74, 788.74, 723.74]\n",
      "Week 3,: [773.74, 753.74, 753.74, 688.74]\n",
      "Week 4,: [738.74, 718.74, 718.74, 653.74]\n",
      "Week 5,: [703.74, 683.74, 683.74, 618.74]\n",
      "Week 6,: [668.74, 648.74, 648.74, 583.74]\n",
      "Week 7,: [633.74, 613.74, 613.74, 548.74]\n",
      "Week 8,: [598.74, 578.74, 578.74, 513.74]\n",
      "Week 9,: [563.74, 543.74, 543.74, 478.74]\n",
      "Week 10,: [528.74, 508.74, 508.74, 443.74]\n",
      "Week 11,: [493.74, 473.74, 473.74, 408.74]\n",
      "Week 12,: [458.74, 438.74, 438.74, 373.74]\n",
      "Week 13,: [423.74, 403.74, 403.74, 338.74]\n",
      "Week 14,: [388.74, 368.74, 368.74, 303.74]\n",
      "Week 15,: [353.74, 333.74, 333.74, 268.74]\n",
      "Week 16,: [318.74, 298.74, 298.74, 233.74]\n",
      "Week 17,: [283.74, 263.74, 263.74, 198.33]\n",
      "Week 18,: [248.33, 228.33, 241.92, 162.7]\n",
      "Week 19,: [212.7, 192.7, 213.85, 150.0]\n",
      "Week 20,: [177.7, 157.7, 157.7, 150.0]\n",
      "Week 21,: [200.0, 30.0, 120.0, -50.0]\n"
     ]
    }
   ],
   "source": [
    "probability_matrix = construct_transition_probability_matrix(STATES, ACTIONS)\n",
    "reward_matrix = construct_reward_matrix(STATES, ACTIONS)\n",
    "\n",
    "n_weeks = 20\n",
    "\n",
    "V = np.zeros((len(STATES), n_weeks+1))\n",
    "# V[:,-1] = np.zeros([len(STATES)]) # final state values # FILL ME IN\n",
    "V[STATES[\"RUNNING\"], -1] = 200\n",
    "V[STATES[\"BROKEN_DOWN\"], -1] = 30\n",
    "V[STATES[\"OVERSPEEDING\"], -1] = 120\n",
    "V[STATES[\"DESTROYED\"], -1] = -50\n",
    "\n",
    "policy = {}\n",
    "\n",
    "for t in range(n_weeks - 1, -1, -1):\n",
    "    for state_name, state_idx in STATES.items():\n",
    "        max_value = -np.inf\n",
    "        best_action_name = None\n",
    "        allowed_actions = allowable_action_set(state_name)\n",
    "\n",
    "        for action_name in allowed_actions:\n",
    "            action_idx = ACTIONS[action_name]\n",
    "\n",
    "            # Calculate expected immediate profit for this state-action\n",
    "            immediate_profit = reward_matrix[state_idx, action_idx]\n",
    "\n",
    "            # Calculate expected future value: sum over next states [ P(s'|s,a) * V(s', t+1) ]\n",
    "            # V[:, t+1] contains the optimal values for the start of the *next* week\n",
    "            future_value = np.dot(probability_matrix[state_idx, :, action_idx], V[:, t + 1])\n",
    "\n",
    "            # Total value for this action\n",
    "            current_action_value = immediate_profit + future_value\n",
    "\n",
    "            # Check if this action is better than the best found so far\n",
    "            if current_action_value > max_value:\n",
    "                max_value = current_action_value\n",
    "                best_action_name = action_name\n",
    "\n",
    "        # Store the optimal value and policy for this state and time step\n",
    "        V[state_idx, t] = max_value\n",
    "        # Store policy keyed by state name and time index t (0 to 19)\n",
    "        policy[(state_name, t)] = best_action_name\n",
    "\n",
    "print(STATES)\n",
    "for t in range(n_weeks):\n",
    "    print(\"Week %i,:\"%(t+1), [policy[(state, t)] for state in STATES.keys()])\n",
    "    \n",
    "for t in range(n_weeks+1):\n",
    "    print(\"Week %i,:\"%(t+1), [np.round(V[(STATES[state], t)], 2).item() for state in STATES.keys()])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
