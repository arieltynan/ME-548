{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tynan 548 Project File\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP X \n",
    "What this step does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cvxpy as cp # import cvxpy\n",
    "\n",
    "# in this problem, we will use the dynamaxsys library to import dynamical systems implemented in JAX: https://github.com/UW-CTRL/dynamaxsys\n",
    "from dynamaxsys.simplecar import DynamicallyExtendedSimpleCar\n",
    "from dynamaxsys.base import get_discrete_time_dynamics\n",
    "from dynamaxsys.utils import linearize\n",
    "\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import numpy as np\n",
    "import functools\n",
    "from ipywidgets import interact\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following segment involves the rover going from the starting point to the first sampling location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the robot dynamics\n",
    "wheelbase = 1.0\n",
    "dt = 0.1\n",
    "ct_robot_dynamics = DynamicallyExtendedSimpleCar(wheelbase=wheelbase) # robot dynamics\n",
    "dt_robot_dynamics = get_discrete_time_dynamics(ct_robot_dynamics, dt=dt) # discrete time dynamics\n",
    "state_dim = dt_robot_dynamics.state_dim\n",
    "control_dim = dt_robot_dynamics.control_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the problem parameters\n",
    "planning_horizon = 20 # 20 # length of the planning horizon\n",
    "num_time_steps = 150 # number of time steps to simulate\n",
    "num_sqp_iterations = 15 # 15 # number of SQP iterations\n",
    "t = 0. # this doesn't affect anything, but a value is needed \n",
    "\n",
    "# control and velocity limits\n",
    "v_max = 2.5 #2 m/s\n",
    "v_min = 0.05 # 0.2 m/s\n",
    "acceleration_max = 3.0 #2/-2  m/s/s\n",
    "acceleration_min = -3.0 # m/s/s\n",
    "steering_max = 2. #started 0.5/-0.5 # radians/sec\n",
    "steering_min = -2. # radians/sec\n",
    "\n",
    "# obstacle parameters\n",
    "\n",
    "robot_radius = 0.1 # robot radius\n",
    "goal_locations = [jnp.array([6.11, 1.44]), jnp.array([5.87, 1.19]), jnp.array([6.29, 0.84]), jnp.array([7.33, 0.15]), jnp.array([7.44, 3.35]), jnp.array([8.2, 7.8]), \n",
    "                  jnp.array([0.87, 6.25]), jnp.array([0.20, 4.68]), jnp.array([-0.13, 5.23]), jnp.array([0.17, 4.77]), jnp.array([0.83, 6.18]), jnp.array([-2.28, 8.40])]\n",
    "goal_location = goal_locations[0]\n",
    "goal_radius = 0.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Establish Rectangle Class ## \n",
    "\n",
    "class Rectangle:\n",
    "    def __init__(self, center, length, width, buffer=0.15): # 0.4 # 0.25 buffer makes robot go narrow way\n",
    "        \"\"\"\n",
    "        Initialize a rectangular obstacle.\n",
    "\n",
    "        Args:\n",
    "            center (tuple or jnp.ndarray): (x, y) coordinates of the center.\n",
    "            length (float): Length along the x-axis.\n",
    "            width (float): Width along the y-axis.\n",
    "            buffer (float): Optional buffer space for inflation.\n",
    "        \"\"\"\n",
    "        self.center = jnp.array(center)\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "        self.buffer = buffer\n",
    "\n",
    "    def inflated_half_lengths(self):\n",
    "        return (self.length / 2 + self.buffer, self.width / 2 + self.buffer)\n",
    "\n",
    "    def as_array(self):\n",
    "        \"\"\"Returns center and dimensions as a single array.\"\"\"\n",
    "        return jnp.array([*self.center, self.length, self.width, self.buffer])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Rectangle(center={self.center.tolist()}, l={self.length}, w={self.width}, buffer={self.buffer})\"\n",
    "\n",
    "\n",
    "\n",
    "## Establish Circle Class ## \n",
    "\n",
    "class Circle:\n",
    "    def __init__(self, center, radius, buffer=0.2): # 0.4 # 0.25 buffer makes robot go narrow way\n",
    "        \"\"\"\n",
    "        Initialize a circular obstacle.\n",
    "\n",
    "        Args:\n",
    "            center (tuple or jnp.ndarray): (x, y) coordinates of the center.\n",
    "            radius (float)\n",
    "            buffer (float): Optional buffer space for inflation.\n",
    "        \"\"\"\n",
    "        self.center = jnp.array(center)\n",
    "        self.radius = radius\n",
    "        self.buffer = buffer\n",
    "\n",
    "    def as_array(self):\n",
    "        \"\"\"Returns center and dimensions as a single array.\"\"\"\n",
    "        return jnp.array([*self.center, self.radius, self.buffer])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Circle(center={self.center.tolist()}, buffer={self.buffer})\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1243,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Init Constraint Objects\n",
    "\n",
    "\n",
    "## Rectangle Obstacles\n",
    "rectangles = [\n",
    "    #Rectangle(center=(0.2, 6.0), length=0.6, width=0.6),\n",
    "    #Rectangle(center=(-0.2, 6.4), length=0.6, width=0.6),\n",
    "    Rectangle(center=(0.0, 0.0), length=0.5, width=0.5)\n",
    "]\n",
    "\n",
    "## Circle caps for rectangle obstacles\n",
    "circles = [\n",
    "    Circle(center=(6.8, 2.2), radius=0.8),\n",
    "    Circle(center=(6.0, 3.6), radius=1.2),\n",
    "    Circle(center=(6.9, 5.8), radius=1.7),\n",
    "    Circle(center=(7.1, 4.0), radius=0.3),\n",
    "    Circle(center=(4.7, 4.3), radius=1.6),\n",
    "    Circle(center=(2.5, 8.9), radius=2.2),\n",
    "    Circle(center=(0.3, 5.8), radius=0.35),\n",
    "    Circle(center=(0.0, 6.3), radius=0.35),    \n",
    "    Circle(center=(-0.3, 6.8), radius=0.3), # breaking?\n",
    "    Circle(center=(-0.55, 7.2), radius=0.35),\n",
    "    Circle(center=(-0.8, 7.7), radius=0.35),\n",
    "    Circle(center=(-1.2, 3.5), radius=1.2)\n",
    "]\n",
    "\n",
    "\n",
    "## Rectangle CBF ##\n",
    "CBF_object = Rectangle(center=(2.0,4.5), length=16.0, width=9.0) #boundary robot stays within\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS #\n",
    "\n",
    "# define obstacle function g(x) >= 0\n",
    "# where g(x) is the distance from the obstacle\n",
    "@jax.jit\n",
    "def circle_constraint(state, obstacle, radius, buffer):\n",
    "    return jnp.linalg.norm(state[:2] - obstacle[:2]) - radius - buffer\n",
    "\n",
    "\n",
    "def smooth_max(a, b, alpha=5.0):\n",
    "    return (1/alpha) * jnp.log(jnp.exp(alpha * a) + jnp.exp(alpha * b))\n",
    "\n",
    "@jax.jit\n",
    "def rect_constraint_smooth(state, obstacle, l, w, buffer, alpha=5.0):\n",
    "    dx = jnp.abs(state[0] - obstacle[0]) - l / 2 - buffer\n",
    "    dy = jnp.abs(state[1] - obstacle[1]) - w / 2 - buffer\n",
    "    return smooth_max(dx, dy, alpha=alpha)\n",
    "\n",
    "# define goal function g(x) >= 0\n",
    "# where g(x) is the distance from the goal\n",
    "\n",
    "@jax.jit\n",
    "def goal_constraint(state, goal, radius):\n",
    "    return jnp.linalg.norm(state[:2] - goal[:2]) - radius\n",
    "\n",
    "\n",
    "# function to simulate the discrete time dynamics given initial state and control sequence\n",
    "@functools.partial(jax.jit, static_argnames=[\"dt_dynamics\"])\n",
    "def simulate_discrete_time_dynamics(dt_dynamics, state, controls, t0, dt):\n",
    "    states = [state]\n",
    "    t = t0\n",
    "    for c in controls:\n",
    "\n",
    "        state = dt_dynamics(state, c, t)\n",
    "        states.append(state)\n",
    "        t += dt\n",
    "    return jnp.stack(states)\n",
    "\n",
    "# function to simulate the discrete time dynamics given initial state and control sequence\n",
    "# function slightly modified to add noise \n",
    "@functools.partial(jax.jit, static_argnames=[\"dt_dynamics\"])\n",
    "def simulate_discrete_time_dynamics_with_noise(dt_dynamics, state, controls, t0, dt, noises):\n",
    "    states = [state]\n",
    "    t = t0\n",
    "    for (c,noise) in zip(controls, noises):\n",
    "        state = dt_robot_dynamics(state, c, t + noise * dt) # take out noises for now\n",
    "        states.append(state)\n",
    "        t += dt\n",
    "    return jnp.stack(states, -1)\n",
    "\n",
    "# jit the linearize constraint functions to make it run faster\n",
    "linearize_circle = jax.jit(jax.vmap(jax.grad(circle_constraint), in_axes=[0, None, None, None]))\n",
    "linearize_goal = jax.jit(jax.vmap(jax.grad(goal_constraint), in_axes=[0, None, None]))\n",
    "linearize_rect_smooth = jax.jit(\n",
    "    jax.vmap(jax.grad(rect_constraint_smooth, argnums=0), in_axes=[0, None, None, None, None])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up cvxpy problem variables and parameters\n",
    "xs = cp.Variable([planning_horizon+1, state_dim])  # cvx variable for states\n",
    "us = cp.Variable([planning_horizon, control_dim])  # cvx variable for controls\n",
    "slack = cp.Variable(1) # slack variable to make sure the problem is feasible\n",
    "As = [cp.Parameter([state_dim, state_dim]) for _ in range(planning_horizon)]  # parameters for linearized dynamics\n",
    "Bs = [cp.Parameter([state_dim, control_dim]) for _ in range(planning_horizon)] # parameters for linearized dynamics\n",
    "Cs = [cp.Parameter([state_dim]) for _ in range(planning_horizon)] # parameters for linearized dynamics\n",
    "\n",
    "\n",
    "Gs_circs = [[cp.Parameter([state_dim]) for _ in range(planning_horizon + 1)] for _ in range(len(circles))]\n",
    "hs_circs = [[cp.Parameter(1) for _ in range(planning_horizon + 1)] for _ in range(len(circles))]\n",
    "\n",
    "Gs_rects = [[cp.Parameter([state_dim]) for _ in range(planning_horizon + 1)] for _ in range(len(rectangles))]\n",
    "hs_rects = [[cp.Parameter(1) for _ in range(planning_horizon + 1)] for _ in range(len(rectangles))]\n",
    "\n",
    "Gs_CBF = [cp.Parameter([state_dim]) for _ in range(planning_horizon+1)] # parameters for linearized constraints CBF\n",
    "hs_CBF = [cp.Parameter(1) for _ in range(planning_horizon+1)] # parameters for linearized constraints CBF\n",
    "\n",
    "\n",
    "Goal_Gs = [cp.Parameter([state_dim]) for _ in range(planning_horizon+1)] # parameters for linearized constraints\n",
    "Goal_hs = [cp.Parameter(1) for _ in range(planning_horizon+1)] # parameters for linearized constraints\n",
    "\n",
    "xs_previous = cp.Parameter([planning_horizon+1, state_dim]) # parameter for previous solution\n",
    "us_previous = cp.Parameter([planning_horizon, control_dim]) # parameter for previous solution\n",
    "initial_state = cp.Parameter([state_dim]) # parameter for current robot state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up cvxpy problem cost and constraints\n",
    "def construct_problem(goal_location):\n",
    "    beta1 = 0.2 # coefficient for control effort\n",
    "    beta2 = 5. # coefficient for progress\n",
    "    beta3 = 10. # coefficient for trust region\n",
    "    slack_penalty = 1000. # coefficient for slack variable\n",
    "    markup = 1.0\n",
    "    goal_cost_weight = 15. # 10\n",
    "    forward_velocity_weight = 0.1 # prev 0.1 # encourage robot to keep moving forward\n",
    "    v_min = 0.0\n",
    "    proximity_buffer = .7 # prox DISTANCE of robot to obstacles, soft discourage\n",
    "    proximity_weight = 3.\n",
    "    turning_penalty = 3.0\n",
    "\n",
    "    ## removed objective beta2 * (xs[-1,2]**2 + xs[-1,1]**2 - xs[-1,0])\n",
    "\n",
    "    # Discourages large changes in state and control\n",
    "    objective = beta3 * (cp.sum_squares(xs - xs_previous) + cp.sum_squares(us - us_previous)) + slack_penalty * slack**2\n",
    "\n",
    "    constraints = [xs[0] == initial_state, slack >= 0] # initial state and slack constraint\n",
    "    for t in range(planning_horizon):\n",
    "        objective += (beta1 * cp.sum_squares(us[t]) ) * markup**t # only penalizes control effort\n",
    "        #terminal_goal_dist_sq = cp.sum_squares(xs[planning_horizon, :2] - goal_location) * markup**t\n",
    "        #objective += terminal_goal_weight * terminal_goal_dist_sq\n",
    "\n",
    "\n",
    "            # NEW: Encourage steady progress toward the goal\n",
    "        step_goal_dist_sq = cp.sum_squares(xs[t, :2] - goal_location)\n",
    "        objective += goal_cost_weight * step_goal_dist_sq * markup**t\n",
    "        objective += -forward_velocity_weight * cp.sum(xs[:, 2]) * markup # encourages movement\n",
    "\n",
    "        constraints += [xs[t+1] == As[t] @ xs[t] + Bs[t] @ us[t] + Cs[t]] # dynamics constraint\n",
    "        constraints += [xs[t,-1] <= v_max, xs[t,-1] >= v_min, us[t,1] <= acceleration_max, us[t,1] >= acceleration_min, us[t,0] <= steering_max, us[t,0] >= steering_min] # control and velocity limit constraints\n",
    "        \n",
    "        #constraints += [Gs[t] @ xs[t] + hs[t] >= -slack] # linearized collision avoidance constraint for obstacles\n",
    "\n",
    "        # Penalize sharp changes in direction\n",
    "        heading_diff = xs[t+1, 2] - xs[t, 2]\n",
    "        objective += turning_penalty * cp.sum_squares(heading_diff)\n",
    "\n",
    "        # Soft penalize going close to obstacles\n",
    "        for r_idx in range(len(Gs_rects)):\n",
    "            constraints += [Gs_rects[r_idx][t] @ xs[t] + hs_rects[r_idx][t] >= 0]\n",
    "            dist = Gs_rects[r_idx][t] @ xs[t] + hs_rects[r_idx][t]\n",
    "            # Penalty if within 1m of obstacle edge: (1 - dist)^2 if dist < 1\n",
    "            objective += proximity_weight * cp.pos(proximity_buffer - dist)**2\n",
    "\n",
    "        for r_idx in range(len(Gs_circs)):\n",
    "            constraints += [Gs_circs[r_idx][t] @ xs[t] + hs_circs[r_idx][t] >= 0]\n",
    "            dist = Gs_circs[r_idx][t] @ xs[t] + hs_circs[r_idx][t]\n",
    "            # Penalty if within 1m of obstacle edge: (1 - dist)^2 if dist < 1\n",
    "            objective += proximity_weight * cp.pos(proximity_buffer - dist)**3\n",
    "\n",
    "\n",
    "        # CBF, rectangle allowable traversable range\n",
    "        #constraints += [Gs_CBF[t] @ xs[t] + hs_CBF[t] <= 0]\n",
    "        constraints += [Gs_CBF[t] @ xs[t] + hs_CBF[t] <= 0]\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    #####\n",
    "    constraints += [xs[planning_horizon,-1] <= v_max, xs[planning_horizon,-1] >= v_min] #,\n",
    "                #Gs[planning_horizon] @ xs[planning_horizon] + hs[planning_horizon] >= -slack]\n",
    "\n",
    "    # Process rectangular obstacles final timestep\n",
    "    for r_idx in range(len(Gs_rects)):\n",
    "        constraints += [Gs_rects[r_idx][planning_horizon] @ xs[planning_horizon] + hs_rects[r_idx][planning_horizon] >= -slack]\n",
    "\n",
    "    # Process circular obstacles final timestep\n",
    "    for r_idx in range(len(Gs_circs)):\n",
    "        constraints += [Gs_circs[r_idx][planning_horizon] @ xs[planning_horizon] + hs_circs[r_idx][planning_horizon] >= -slack]\n",
    "\n",
    "\n",
    "\n",
    "    return cp.Problem(cp.Minimize(objective), constraints) # construct problem\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Replan at each timestep!\n",
    "Hopefully you saw from above the need to replan at each time step.\n",
    "Run the following cells and answer the question at the end.\n",
    "\n",
    "(Just run the cell below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial states\n",
    "robot_state = jnp.array([goal_locations[0][0], goal_locations[0][1], 0., 1.])  # robot starting state 92.38, 0.0977\n",
    "\n",
    "robot_trajectory = [robot_state] # list to collect robot's state as it replans\n",
    "sqp_list = [] # list to collect each sqp iteration \n",
    "robot_control_list = []  # list to collect robot's constrols as it replans\n",
    "robot_trajectory_list = [] # list to collect robot's planned trajectories\n",
    "\n",
    "# initial robot planned state and controls\n",
    "previous_controls = jnp.zeros([planning_horizon, control_dim]) # initial guess for robot controls\n",
    "previous_states =  simulate_discrete_time_dynamics(dt_robot_dynamics, robot_state, previous_controls, 0., dt) # initial guess for robot states\n",
    "xs_previous.value = np.array(previous_states) # set xs_previous parameter value\n",
    "us_previous.value = np.array(previous_controls) # set us_previous parameter value \n",
    "\n",
    "# precompute the noise\n",
    "key = jax.random.PRNGKey(0)\n",
    "noise_covar = jnp.diag(jnp.array([0.1, 0.1, 0.05, 0.2])) # noise covariance\n",
    "noises = jax.random.multivariate_normal(key, jnp.zeros(robot_state.shape), noise_covar, shape=(num_time_steps,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun the simulation, replanning at each time step, and adding some noise when computing the robot's next state.\n",
    "\n",
    "(Just run the cell below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point 0 sampled at sol 0. Searching for Point 1 at [5.87 1.19].\n",
      "Point 1 sampled at sol 2. Searching for Point 2 at [6.29 0.84].\n",
      "Point 2 sampled at sol 7. Searching for Point 3 at [7.33 0.15].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ariel\\anaconda3\\envs\\ME548\\Lib\\site-packages\\cvxpy\\problems\\problem.py:1504: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point 3 sampled at sol 16. Searching for Point 4 at [7.44 3.35].\n",
      "No solution found\n",
      "Point 4 sampled at sol 33. Searching for Point 5 at [8.2 7.8].\n",
      "No solution found\n",
      "Point 5 sampled at sol 56. Searching for Point 6 at [0.87 6.25].\n",
      "Point 6 sampled at sol 89. Searching for Point 7 at [0.2  4.68].\n",
      "No solution found\n",
      "Point 7 sampled at sol 99. Searching for Point 8 at [-0.13  5.23].\n",
      "Point 8 sampled at sol 105. Searching for Point 9 at [0.17 4.77].\n",
      "Point 9 sampled at sol 109. Searching for Point 10 at [0.83 6.18].\n",
      "Point 10 sampled at sol 120. Searching for Point 11 at [-2.28  8.4 ].\n",
      "No solution found\n",
      "All goals reached!\n"
     ]
    }
   ],
   "source": [
    "prob = construct_problem(goal_location)\n",
    "solver = cp.CLARABEL\n",
    "goal_index = 0\n",
    "for t in range(num_time_steps):\n",
    "    \n",
    "    goal_threshold = 0.2  # adjust threshold as needed\n",
    "    distance_to_goal = np.linalg.norm(robot_state[:2] - goal_location)\n",
    "    if distance_to_goal < goal_threshold:\n",
    "        if goal_index < len(goal_locations) - 1: #stop resetting goal after last goal reached\n",
    "            goal_location = goal_locations[goal_index + 1]\n",
    "            goal_index += 1\n",
    "            print(f\"Point {goal_index - 1} sampled at sol {t}. Searching for Point {goal_index} at {goal_location}.\")\n",
    "                    \n",
    "        else:\n",
    "            print(f\"Point {goal_index} sampled at sol {t}. All goals reached!\")\n",
    "            break\n",
    "\n",
    "        # Reset velocity\n",
    "        #robot_state = robot_state.at[-1].set(0)\n",
    "\n",
    "        # Reorient toward next goal\n",
    "        robot_control[:] = 0\n",
    "        delta = goal_location - robot_state[:2]\n",
    "        new_heading = np.arctan2(delta[1], delta[0])\n",
    "        robot_state = robot_state.at[2].set(new_heading)\n",
    "\n",
    "        prob = construct_problem(goal_location)  # rebuild with new goal\n",
    "        solver = cp.CLARABEL\n",
    "\n",
    "        previous_states = np.tile(np.array(robot_state), (planning_horizon + 1, 1))\n",
    "        previous_controls = np.zeros((planning_horizon, control_dim))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    initial_state.value = np.array(robot_state)\n",
    "    sqp_solutions = [previous_states]\n",
    "\n",
    "    \n",
    "    for i in range(num_sqp_iterations):\n",
    "        #print(\"goal location in sqp loop:\", goal_location)\n",
    "        As_value, Bs_value, Cs_value = jax.vmap(linearize, in_axes=[None, 0, 0, None])(dt_robot_dynamics, previous_states[:-1], previous_controls, 0.)\n",
    "        #Gs_value = linearize_obstacle(previous_states, obstacle_location, obstacle_radius + robot_radius) \n",
    "        #hs_value = jax.vmap(obstacle_constraint, [0, None, None])(previous_states, obstacle_location, obstacle_radius + robot_radius) - jax.vmap(jnp.dot, [0, 0])(Gs_value, previous_states)\n",
    "    \n",
    "        # Init vectors for batch rectangle and circle obstacles\n",
    "        Gs_rects_values = []\n",
    "        hs_rects_values = []\n",
    "        Gs_circs_values = []\n",
    "        hs_circs_values = []\n",
    "\n",
    "        for rect in rectangles:\n",
    "            G_val = linearize_rect_smooth(previous_states, rect.center, rect.length, rect.width, rect.buffer)\n",
    "            h_val = (\n",
    "                jax.vmap(rect_constraint_smooth, [0, None, None, None, None])(previous_states, rect.center, rect.length, rect.width, rect.buffer)\n",
    "                - jax.vmap(jnp.dot, [0, 0])(G_val, previous_states)\n",
    "            )\n",
    "            Gs_rects_values.append(G_val)\n",
    "            hs_rects_values.append(h_val)\n",
    "\n",
    "        for circ in circles:\n",
    "            G_val = linearize_circle(previous_states, circ.center, circ.radius, circ.buffer)\n",
    "            h_val = (\n",
    "                jax.vmap(circle_constraint, [0, None, None, None])(previous_states, circ.center, circ.radius, circ.buffer)\n",
    "                - jax.vmap(jnp.dot, [0, 0])(G_val, previous_states)\n",
    "            )\n",
    "            Gs_circs_values.append(G_val)\n",
    "            hs_circs_values.append(h_val)\n",
    "\n",
    "\n",
    "        Gs_CBF_value = linearize_rect_smooth(previous_states, CBF_object.center, CBF_object.length, CBF_object.width, CBF_object.buffer)\n",
    "        hs_CBF_value = (\n",
    "                jax.vmap(rect_constraint_smooth, [0, None, None, None, None])(previous_states, CBF_object.center, CBF_object.length, CBF_object.width, CBF_object.buffer)\n",
    "                - jax.vmap(jnp.dot, [0, 0])(Gs_CBF_value, previous_states))\n",
    "\n",
    "\n",
    "        Goal_Gs_value = linearize_goal(previous_states, goal_location, goal_radius + robot_radius) \n",
    "        Goal_hs_value = jax.vmap(goal_constraint, [0, None, None])(previous_states, goal_location, goal_radius + robot_radius) - jax.vmap(jnp.dot, [0, 0])(Goal_Gs_value, previous_states)\n",
    "\n",
    "        for i in range(planning_horizon):\n",
    "            As[i].value = np.array(As_value[i])\n",
    "            Bs[i].value = np.array(Bs_value[i])\n",
    "            Cs[i].value = np.array(Cs_value[i])\n",
    "            #Gs[i].value = np.array(Gs_value[i])\n",
    "            #hs[i].value = np.array(hs_value[i:i+1])\n",
    "\n",
    "            Goal_Gs[i].value = np.array(Goal_Gs_value[i])\n",
    "            Goal_hs[i].value = np.array(Goal_hs_value[i:i+1])\n",
    "\n",
    "                # Handle all rectangle and circle constraints\n",
    "            for r_idx in range(len(rectangles)):\n",
    "                Gs_rects[r_idx][i].value = np.array(Gs_rects_values[r_idx][i])\n",
    "                hs_rects[r_idx][i].value = np.array(hs_rects_values[r_idx][i:i+1])\n",
    "\n",
    "            for r_idx in range(len(circles)):\n",
    "                Gs_circs[r_idx][i].value = np.array(Gs_circs_values[r_idx][i])\n",
    "                hs_circs[r_idx][i].value = np.array(hs_circs_values[r_idx][i:i+1])\n",
    "\n",
    "            Gs_CBF[i].value = np.array(Gs_CBF_value[i])\n",
    "            hs_CBF[i].value = np.array(hs_CBF_value[i:i+1])\n",
    "\n",
    "\n",
    "        Goal_Gs[planning_horizon].value = np.array(Goal_Gs_value[planning_horizon])\n",
    "        Goal_hs[planning_horizon].value = np.array(Goal_hs_value[planning_horizon:planning_horizon+1])\n",
    "\n",
    "        for r_idx in range(len(rectangles)):\n",
    "            Gs_rects[r_idx][planning_horizon].value = np.array(Gs_rects_values[r_idx][planning_horizon])\n",
    "            hs_rects[r_idx][planning_horizon].value = np.array(hs_rects_values[r_idx][planning_horizon:planning_horizon+1])\n",
    "\n",
    "        for r_idx in range(len(circles)):\n",
    "            Gs_circs[r_idx][planning_horizon].value = np.array(Gs_circs_values[r_idx][planning_horizon])\n",
    "            hs_circs[r_idx][planning_horizon].value = np.array(hs_circs_values[r_idx][planning_horizon:planning_horizon+1])\n",
    "\n",
    "        Gs_CBF[planning_horizon].value = np.array(Gs_CBF_value[planning_horizon])\n",
    "        hs_CBF[planning_horizon].value = np.array(hs_CBF_value[planning_horizon:planning_horizon+1])\n",
    "\n",
    "\n",
    "        result = prob.solve(solver=solver)\n",
    "\n",
    "        if us.value is None:\n",
    "            print(\"No solution found\")\n",
    "            break\n",
    "\n",
    "        previous_controls = us.value\n",
    "        previous_states =  simulate_discrete_time_dynamics(dt_robot_dynamics, robot_state, previous_controls, 0., dt)\n",
    "        sqp_solutions.append(previous_states)\n",
    "        xs_previous.value = np.array(previous_states)\n",
    "        us_previous.value = np.array(previous_controls)\n",
    "\n",
    "    sqp_list.append(np.stack(sqp_solutions))\n",
    "    robot_control = previous_controls[0]\n",
    "    robot_control_list.append(robot_control)\n",
    "    \n",
    "    # get the robot next state using the control input\n",
    "    robot_state = dt_robot_dynamics(robot_state, robot_control, noises[t] * dt) \n",
    "    \n",
    "    # clipping the robot velocity so the problem doesn't become infeasible at the next step\n",
    "    robot_state = robot_state.at[3].set(jnp.clip(robot_state[3], v_min, v_max)) \n",
    "    \n",
    "    # add robot state and trajectory to the list\n",
    "    robot_trajectory.append(robot_state)\n",
    "    robot_trajectory_list.append(previous_states)\n",
    "    \n",
    "    # update the previous states and controls for the next iteration\n",
    "    previous_states =  simulate_discrete_time_dynamics(dt_robot_dynamics, robot_state, previous_controls, 0., dt)\n",
    "\n",
    "robot_trajectory = jnp.stack(robot_trajectory)\n",
    "robot_controls = jnp.stack(robot_control_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results!\n",
    "\n",
    "(Just run the cell below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b609d4bda5af41479927007571e4dbf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=74, description='i', max=149), IntSlider(value=7, description='j', max=1â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the results. No need to add comments here. Just run this cell to visualize the results\n",
    "@interact(i=(0,num_time_steps-1), j=(0,num_sqp_iterations-1))\n",
    "\n",
    "def plot(i, j):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(24, 8), gridspec_kw={'width_ratios': [2, 1]})\n",
    "    # fig, axs = plt.subplots(1,2, figsize=(10, 4))\n",
    "    ax = axs[0]\n",
    "    robot_position = robot_trajectory[i, :2]\n",
    "    circle1 = plt.Circle(robot_position, robot_radius, color='C0', alpha=0.4)\n",
    "    #circle2 = plt.Circle(obstacle_location, obstacle_radius, color='C1', alpha=0.4)\n",
    "    #circle3 = plt.Circle(obstacle_location2, obstacle_radius, color='C1', alpha=0.4)\n",
    "    \n",
    "    # plot goals\n",
    "    for count in range(0, len(goal_locations)):\n",
    "        ax.add_patch(plt.Circle(goal_locations[count], goal_radius, color='C2', alpha=0.6))\n",
    "                \n",
    "        # Add goal index label at the center\n",
    "        ax.text(\n",
    "            goal_locations[count][0],                # x-coordinate\n",
    "            goal_locations[count][1],                # y-coordinate\n",
    "            str(count),                                 # text to display\n",
    "            color='black',                              # text color\n",
    "            fontsize=10,                                # size of the number\n",
    "            ha='center',                                # horizontal alignment\n",
    "            va='center',                                # vertical alignment\n",
    "            fontweight='bold'\n",
    "        )\n",
    "    \n",
    "    for count in range(0, len(rectangles)):\n",
    "        bottom_left = rectangles[count].center - jnp.array([rectangles[count].length / 2, rectangles[count].width / 2])\n",
    "        rect_plot = patches.Rectangle(\n",
    "            bottom_left,\n",
    "            rectangles[count].length,            # length along x\n",
    "            rectangles[count].width,            # width along y\n",
    "            linewidth=1,\n",
    "            edgecolor='C1',\n",
    "            facecolor='C1',\n",
    "            alpha=0.4\n",
    "        )\n",
    "        #ax.add_patch(rect_plot)\n",
    "\n",
    "        # Add rectangle index label at the center\n",
    "        ax.text(\n",
    "            rectangles[count].center[0],                # x-coordinate\n",
    "            rectangles[count].center[1],                # y-coordinate\n",
    "            str( ''),                                 # text to display\n",
    "            color='black',                              # text color\n",
    "            fontsize=10,                                # size of the number\n",
    "            ha='center',                                # horizontal alignment\n",
    "            va='center',                                # vertical alignment\n",
    "            fontweight='bold'\n",
    "        )\n",
    "\n",
    "    for count in range(0, len(circles)):\n",
    "        circ_plot = patches.Circle(circles[count].center, circles[count].radius, color='C1', alpha=0.4)\n",
    "        ax.add_patch(circ_plot)\n",
    "        # Add rectangle index label at the center\n",
    "        ax.text(\n",
    "            circles[count].center[0],                # x-coordinate\n",
    "            circles[count].center[1],                # y-coordinate\n",
    "            str(count),                                 # text to display\n",
    "            color='black',                              # text color\n",
    "            fontsize=10,                                # size of the number\n",
    "            ha='center',                                # horizontal alignment\n",
    "            va='center',                                # vertical alignment\n",
    "            fontweight='bold'\n",
    "        )\n",
    "\n",
    "    # Plot CBF object\n",
    "    bottom_left = CBF_object.center - jnp.array([CBF_object.length / 2, CBF_object.width / 2])\n",
    "    rect_plot = patches.Rectangle(\n",
    "        bottom_left,\n",
    "        CBF_object.length,            # length along x\n",
    "        CBF_object.width,            # width along y\n",
    "        linewidth=1,\n",
    "        edgecolor='C2',\n",
    "        facecolor='#E0E0E0',\n",
    "        alpha=0.4\n",
    "    )\n",
    "    ax.add_patch(rect_plot)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ax.add_patch(circle1)\n",
    "    #ax.add_patch(circle2)\n",
    "    #ax.add_patch(circle3)\n",
    "    #plot_polygon_obstacle(polygon, ax)\n",
    "    ax.plot(robot_trajectory[:,0], robot_trajectory[:,1], \"o-\", markersize=1, color='grey')\n",
    "    ax.plot(robot_trajectory_list[i][:,0], robot_trajectory_list[i][:,1], \"o-\", markersize=3, color='red', label=\"Planned\")\n",
    "    # Plot planned trajectory for the selected SQP iteration\n",
    "\n",
    "    #planned_trajectory = sqp_list[i][j]\n",
    "\n",
    "    if i < len(sqp_list) and j < len(sqp_list[i]):\n",
    "        planned_trajectory = sqp_list[i][j]\n",
    "        ax.plot(planned_trajectory[:, 0], planned_trajectory[:, 1], \"o-\", markersize=3, color='green', alpha=0.4, label=f\"SQP iteration {j}\")\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, f\"No SQP {j} at step {i}\", transform=ax.transAxes, ha='center', va='center', fontsize=12, color='red')\n",
    "\n",
    "    #ax.plot(planned_trajectory[:, 0], planned_trajectory[:, 1], \"o-\", markersize=3, color='green', alpha=0.4, label=\"SQP iteration %d\" % j)\n",
    "    ax.scatter(robot_trajectory[i:i+1,0], robot_trajectory[i:i+1,1], s=30,  color='C100', label=\"Robot\")\n",
    "    ax.set_xlim([-2, 7])\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    ax.axis(\"equal\")\n",
    "\n",
    "    ax.set_title(\"heading=%.2f velocity=%.2f\"%(robot_trajectory[i,2], robot_trajectory[i,3]))\n",
    "    \n",
    "    ax = axs[1]\n",
    "    ax.plot(robot_controls)\n",
    "    ax.scatter([i], robot_controls[i:i+1, 0], label=\"$tan(\\\\delta)$\", color='C0')\n",
    "    ax.scatter([i], robot_controls[i:i+1, 1], label=\"Acceleration\", color='C1')\n",
    "\n",
    "    ax.hlines(steering_min, 0, num_time_steps-1, color='C0', linestyle='--')\n",
    "    ax.hlines(steering_max, 0, num_time_steps-1, color='C0', linestyle='--')\n",
    "    ax.hlines(acceleration_min, 0, num_time_steps-1, color='C1', linestyle='--')\n",
    "    ax.hlines(acceleration_max, 0, num_time_steps-1, color='C1', linestyle='--')\n",
    "    \n",
    "    ax.plot(robot_trajectory[:,-1], markersize=3, color='C2')\n",
    "    ax.scatter([i], robot_trajectory[i:i+1, 3], label=\"Velocity\", color='C2')\n",
    "    ax.hlines(v_min, 0, num_time_steps-1, color='C2', linestyle='--')\n",
    "    ax.hlines(v_max, 0, num_time_steps-1, color='C2', linestyle='--')\n",
    "    ax.set_xlim([0, num_time_steps])\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.set_xlabel(\"Time step\")\n",
    "    ax.set_ylabel(\"Control\")\n",
    "    ax.set_title(\"Velocity, steering and acceleration\")\n",
    "    ax.legend()\n",
    "    ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it guaranteed that your system will not hit the obstacle if we just apply MPC in the way we did above?\n",
    "If not, what are some techniques you could try to reduce the risk of colliding into the obstacles?\n",
    "\n",
    "(Optional) What if the obstacles were not stationary. But rather, they were moving. How would the problem change if the obstacle's motion were fully known (e.g., we knew exactly where the obstacle would be at any point in time), or if the obstacle's motion was uncertain (e.g., the obstacles were pedestrians, or space debris whose motion is not fully known). What are some techniques that could be applied to reduce the risk of collision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not guaranteed the system will not hit the obstacle. In my code, even with MPC applied, the first obstacle appears hit. In this case it was hit due to a sharp change in direction across only one timepoint. This indicates more safety measures should be put in place. Examples of those include increasing the size of the obstacle (similar to CBF applications) to compensate for error. While much more computationally intensive, the timestep frequency could be increased, which would make the magnitude of noise at each timestep smaller and give more opportunities for trajectory correction. Control restrictions can be put on the velocity to restrict movement, which also would give more opportunities for course correction. \n",
    "\n",
    "If the obstacles were moving but the motion was known, that should be able to be factored into the state and the problem should not change much. If the obstacle's motion was uncertain, then the planning horizon would need to be significantly decreased. A long planning horizon is useless if the states change unpredictably, and the desired trajectory may need to change on a whim. Adjusting the controls to allow for more leeway in sharp changes in acceleration would be helpful in dodging swift obstacles moving in the direction of the robot or its trajectory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ME548",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
